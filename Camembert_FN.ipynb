{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camembert fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerate version: 0.29.3\n",
      "Transformers version: 4.40.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import accelerate\n",
    "import transformers\n",
    "print(\"Accelerate version:\", accelerate.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_pd = pd.read_csv('training_data.csv')\n",
    "unlabelled_data_pd = pd.read_csv('unlabelled_test_data.csv')\n",
    "sample_submission_pd = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "training_data_pd = training_data_pd.drop('id', axis=1)\n",
    "#unlabelled_data_pd = unlabelled_data_pd.drop('id', axis=1)\n",
    "#sample_submission_pd = sample_submission_pd.drop('id', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### double the dataframe test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_data_pd = pd.concat([training_data_pd, training_data_pd], ignore_index=True)\n",
    "\n",
    "#print(training_data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_pd = training_data_pd.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### augment data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mooli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package europarl_raw to\n",
      "[nltk_data]     C:\\Users\\mooli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package europarl_raw is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.corpus import europarl_raw\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('europarl_raw')\n",
    "\n",
    "def process_text(input_text, difficulty_level):\n",
    "    french_tokenizer = PunktSentenceTokenizer(europarl_raw.french.raw())\n",
    "\n",
    "    sentences = french_tokenizer.tokenize(input_text)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'sentence': sentences,\n",
    "        'difficulty': [difficulty_level] * len(sentences)\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "input_text = \"Bonjour ! Je m’appelle Claire. À l’école, il y a beaucoup de langues. Je parle anglais et je parle aussi un peu d’italien. Maintenant, j’étudie le français.Je viens d’apprendre comment poser les questions. Comment t’appelles-tu ? Combien de langues est-ce que tu parles ? Je vais visiter la France avec un ami. Il s’appelle Thomas. Nous allons à Paris, pour voir la tour Eiffel et la pyramide du Louvre.Est-ce que tu vas à Paris aussi ? Est-ce que tu aimes le français ? C’est une jolie langue, n’est-ce pas ? Bonjour, je m’appelle Élisabeth. J’ai vingt-neuf ans et je suis française. Je suis née à Lyon mais j’ai grandi à Marseille. Je suis allée à l’université à Paris. Maintenant, j’habite à Strasbourg et je suis ingénieur.Je vous présente ma famille. Mon père est professeur de maths et ma mère est avocate. Ils sont mariés depuis trente ans. J’ai trois frères et quatre sœurs – c’est une grande famille, n’est-ce pas ? Je suis mariée depuis six ans. Mon mari est médecin et nous avons deux enfants : une fille et un fils. J’aime beaucoup voyager : je parle espagnol et allemand. Je viens de rentrer du Portugal, et l’année prochaine, je vais visiter l’Angleterre pour la première fois. Il y a beaucoup d’autres pays que je veux visiter, mais je n’ai pas assez de temps. Bien sûr, je dois travailler, comme tout le monde. Au revoir ! Je vais manger quelque chose … mais quoi ? J’aime la salade, mais je n’ai pas de laitue. Il y a des pâtes, mais il n’y a pas de sauce. J’ai de la soupe, mais il fait trop chaud pour la soupe. Il y a du riz, mais je ne mange pas de riz. Je vois trois pommes de terre, mais elles ne sont pas bonnes. Je vais aller au restaurant ! Bonjour, je m’appelle Élisabeth. J’ai vingt-neuf ans et je suis française. Je suis née à Lyon mais j’ai grandi à Marseille. Je suis allée à l’université à Paris. Maintenant, j’habite à Strasbourg et je suis ingénieur. Je vous présente ma famille. Mon père est professeur de maths et ma mère est avocate. Ils sont mariés depuis trente ans. J’ai trois frères et quatre sœurs – c’est une grande famille, n’est-ce pas ? Je suis mariée depuis six ans. Mon mari est médecin et nous avons deux enfants : une fille et un fils. J’aime beaucoup voyager : je parle espagnol et allemand. Je viens de rentrer du Portugal, et l’année prochaine, je vais visiter l’Angleterre pour la première fois. Il y a beaucoup d’autres pays que je veux visiter, mais je n’ai pas assez de temps. Bien sûr, je dois travailler, comme tout le monde. Au revoir ! \"\n",
    "new_df = process_text(input_text, 'A1')\n",
    "\n",
    "input_text = \"Le premier juillet, c’est la Fête du Canada, la fête nationale du Canada. Dans les années où le premier juillet tombe un dimanche, la plupart des célébrations ont quand même lieu ce jour, mais le lundi 2 juillet sert de fête férié. La fête du Canada commémore le fait de signer l’Acte de l’Amérique du Nord britannique (l’Acte ANB), qui a réuni trois colonies britannique en une dominion fédérale et a défini la plupart du gouvernement canadien. Elle s’appelle à l’origine la Fête du Dominion, mais en 1982, quand le gouvernement britannique a enfin cédé tout contrôle sur le Canada, le premier juillet a été rebaptisé la fête du Canada, et l’Acte ANB a été renommé l’Acte constitutionnelle. La fête du Canada s’appelle aussi l’anniversaire du Canada, et avant 1982, le Fête de la Confédération. Comme les fêtes nationales des USA (le 4 juillet) et de France (le 14 juillet), la Fête du Canada célèbre la création du pays moderne avec des événements de plein air comme des défilés, feu d’artifice et pique-niques. La décoration indispensable d’un Noël français est la crèche, qui se trouve dans les églises, dans les maisons et parfois sur les places publiques. En Provence, les crèches sont souvent un mélange de religion et de quotidien, présentant non seulement la naissance du Christ, mais aussi le village et le mode de vie provençaux, avec des fermes, des magasins et des personnages typiques de la région. Les petites figurines qui peuplent les crèches s’appellent les santons (littéralement, « petits saints »), et la ville d’Aubagne en est la capitale mondiale. Faits en terre cuite ou en argile, on peut acheter des santons peints ou à peindre et créer son propre village provençal. À part les personnages de la bible (Joseph, Marie, l’enfant Jésus, les Rois Mages), la crèche provençale met en vedette beaucoup de personnages typiques parmi lesquels : Il y a aussi beaucoup d’animaux domestiques (âne, bœuf, mouton…), de végétaux (le houx, le laurier-tin, la mousse, l’olivier, le pyracantha, sans oublier le blé de la Sainte Barbe) et aussi, bien sûr, de bâtiments : le moulin, l’étable, les magasins, les mas. Quatre personnages ne sont pas mis dans la crèche au début. En rentrant de la messe de minuit, le benjamin place l’enfant Jésus entre ses Saints Parents. Enfin, le 6 janvier, les Rois mages arrivent et complètent la crèche. Normalement, la crèche est défaite le 2 février avant de fêter la Chandeleur. L’une des questions qu’on me pose le plus souvent, c’est du genre « Je suis en train de perdre mon français ! Comment puis-je le maintenir quand je ne suis pas en France ? » Voici ma réponse. Tout d’abord, je recommande vivement que vous deveniez membre de l’Alliance française. Cette organisation internationale à but non lucratif promeut la langue de Molière partout dans le monde, avec plus de 800 succursales dans environ 135 pays. Elle propose non seulement des cours de français pour tous les niveaux, mais aussi un programme d’activités (conférences, films, dîners…) pour que les adhérents, dont des locuteurs natifs, puissent se réunir pour discuter en français. S’il n’y a pas d’Alliance française près de chez vous, cherchez un club dans une université ou un centre universitaire dans le coin, ou sur le site Meetup, ou bien créez–en un vous-même ! Pourquoi pas ? Vous avez envie de parler français, il y a sans doute d’autres gens dans votre ville qui le veulent aussi. Surtout, ne soyez pas craintif ! La timidité est l’ennemi de l’apprentissage et, surtout, de la pratique d’une langue étrangère. Personne ne va se moquer de vous, vous êtes tous là pour vous éduquer et vous divertir, donc profitez de l’occasion pour parler, avec tous vos défauts. Les réunions hebdomadaires ou mensuelles sont utiles, mais il est également important de faire un peu de français tous les jours : si vous n’avez pas de classe ou de réunion aujourd’hui, vous pouvez étudier, écouter ou lire chez vous. J’ajoute une page à mon site chaque jour, soit une leçon de grammaire ou de vocabulaire, soit un fichier audio, soit une page de compréhension de lecture comme celle-ci. Abonnez-vous à mon infolettre pour recevoir tous ces nouveaux liens deux fois par semaine dans votre boîte à lettres virtuelle, ou bien suivez-moi sur les médias sociaux. Vous pouvez aussi vous familiariser avec les pays et les cultures francophones en écoutant des articles ou en regardant des films, et vous avez la possibilité de suivre l’actualité en lisant un journal français. Peu importe, pourvu que vous passiez du temps avec le français tous les jours.  Autre astuce : suivez-nous sur Facebook, où vous pouvez poser toutes vos questions et discuter des films, de la musique ou encore de la linguistique avec des Francophones et Francophiles du monde entier. C’est un mélange magique d’apprentissage des cultures francophones, des divertissements, de l’amitié – et du français, bien entendu. Et surtout, surtout, n’oubliez pas que vous devez vous engager et faire un effort : trouver de quoi lire, chercher des fichiers audio à écouter, assister aux évènements de votre club, et – je me répète, parce que c’est essentiel – il faut parler, même si vous faites des bêtises. Si vous ne parlez pas, vous perdrez vos connaissances et il deviendra encore plus difficile de parler : c’est un cercle vicieux. En revanche, plus vous parlez, plus vous vous sentirez à l’aise, plus vous aurez envie de parler : un cercle vertueux ! Alors, qu’est-ce que vous attendez ? Au boulot ! Autrefois, les Français faisaient leurs achats dans toute une série de petits magasins spécialisés : le lait et le fromage à la crémerie, la viande chez le boucher, les fruits et les légumes au marché ou bien chez le primeur, et cetera. Depuis des années, avec le développement – et la commodité – des supermarchés, cette habitude se perd. Il est beaucoup plus facile, plus rapide et, en général, moins cher de faire ses courses dans un supermarché, et les petites boutiques disparaissent progressivement.Et ce ne sont pas seulement les magasins d’alimentation qui s’en vont ; les hypermarchés – avec leurs rayons de produits alimentaires, quincaillerie, vêtements, électroménager, jouets et autres produits non comestibles – détournent beaucoup de clients aussi. Résultat : toutes sortes de magasins sont obligés de cesser leurs activités. La seule exception, dans une certaine mesure, semble être les boulangeries. Bref, il se passe en France la même chose que dans beaucoup d’autres pays : les grands magasins mangent les petits, et on échange l’originalité contre la commodité et les prix attractifs. Que l’on soit pour ou contre ces changements, on ne peut pas nier que ça transforme la culture française. Il y a maintes manières de classifier les fromages, et l’une des plus importantes, c’est selon la sorte de lait. Il y en a trois en France : le lait de vache, lait de chèvre et lait de brebis (ce dernier est la femelle du mouton). Une autre classification très importante concerne la méthode de fabrication, à savoir, le type de pâte. Ce sujet est très complexe ; je vous offre juste un aperçu simplifié. Les fromages à pâte fraîche, comme le fromage blanc et la faisselle, ont normalement un goût léger (le chèvre peut être une grande exception). Ces fromages peuvent être fabriqués à partir de lait ou de petit-lait, et se mangent bientôt après leur fabrication. Le fromage à pâte persillée a des moisissures internes et un fort goût : le roquefort, les fromages bleus. Le fromage à pâte pressé ou pâte dure peut être cuit ou pas et est sujet à un affinage entre 3 à 24 mois : beaufort, comté, emmenthal, raclette, mimolette. Signe d’autorité, le premier Grand Sceau de France date du Moyen Âge. Le sceau utilisé de nos jours, défini et frappé en 1848 (IIe République), met en vedette la Liberté, sous forme d’une femme assise, qui tient un faisceau de licteur d’une main et dans l’autre, un gouvernail orné d’un coq gaulois, la patte posée sur un globe. Il y a également une urne, qui rappelle le suffrage universal avec les lettres SU, et des attributs des beaux arts et de l’agriculture à ses pieds. Sur la face est gravé « République française, démocratique, une et indivisible » et au dos « Au nom du peuple français » et « égalité, fraternité ». (La devise française est complète si l’on compte l’image de la Liberté sur l’autre côté.) Ce sceau est repris par les IIIe, IVe et Ve Républiques ; c’est-à-dire que le sceau actuel est le même que celui de 1848. \"\n",
    "new_df = process_text(input_text, 'A2')\n",
    "\n",
    "new_df = pd.concat([new_df, new_df], ignore_index=True)\n",
    "\n",
    "input_text = \"Dans l’arrière-pays de Provence, à 30 kilomètres au sud-ouest de Draguignan, l’Abbaye du Thoronet est un chef-d’œuvre de l’art roman provençal. Figurant parmi les plus remarquables abbayes cisterciennes, elle est la deuxième des « Trois sœurs provençales ». Construit entre 1160 et 1230, le monastère abritait au début une vingtaine de moines et des dizaines de frères convers (chargés de travaux manuels). D’une conception simple qui profite au maximum de la lumière naturelle, l’abbaye a dû être restaurée à partir de 1841, et l’État a commencé à l’acheter en 1854. Aujourd’hui, elle est ouverte toute l’année à l’exception de 5 jours fériés, et on peut choisir entre une visite commentée ou libre. La direction propose aussi des activités culturelles (conférences, ateliers, concerts), une librairie-boutique et, en été, un resto rapide. Nous avons visité l’Abbaye en novembre, un jour où il faisait gris, et nous n’avons donc malheureusement pas vu la belle luminosité pour laquelle elle est célèbre. Nous avions toujours l’intention de suivre la suggestion de la réceptionniste et y retourner en avril pour une deuxième visite ; hélas, nous ne l’avons jamais fait. Pendant presque tout notre séjour à Hyères, mon mari a donné des cours d’anglais dans une association qui s’appelle l’AVF. L’Accueil des villes françaises est une association non gouvernementale et à but non lucratif dont le personnel se compose de bénévoles. Le but des 350 filiales d’AVF dispersées à travers la France est d’aider les nouveaux arrivants dans une ville à s’y intégrer. Bien qu’affiliées, les associations ne suivent pas toutes le même programme, donc les offres de chacune varient. À Hyères, il y a une trentaine d’ateliers proposés : des langues, des jeux et de l’artisanat. Lors de notre dernière année, mon mari avait animé 4 des 5 niveaux de cours d’anglais, et notre départ a secoué l’organisation. Il a passé des mois à essayer de trouver ses remplaçants, avec peu de succès. En fin de compte, l’AVF a dû annuler plusieurs niveaux – c’était vraiment dommage. S’il n’a pas reçu de salaire, mon mari a été récompensé de plusieurs manières pour son travail à l’AVF. D’abord, il adore enseigner (et il est très doué), donc il éprouve une vraie satisfaction en voyant les progrès de ses étudiants, et en recevant leurs remerciements sincères. Deuxièmement, nous nous sommes fait des dizaines d’amis parmi ses étudiants, dont une dizaine nous ont invités à dîner chez eux (une invitation qu’on prétend être très rare parmi les Français). Et troisièmement, à la fin de l’année, les étudiants dans chaque classe se sont cotisés pour lui acheter des cadeaux de remerciement. Cette année, ils ont été particulièrement généreux, lui offrant des tas de cadeaux (des livres, des DVD, du vin, des cartes-cadeaux), aussi bien qu’un poème et même un sketch taquinant gentiment mon mari pour son style très animé d’enseignement. Comment améliorer son français, comment faire euh moins de fautes, euh comment écrire avec un joli style. Alors, vous entendez souvent les professeurs de français euh vous recommander la lecture et on voit parfois euh des étudiants qui sourient quand on leur fait cette recommendation euh comme pour dire euh « vraiment la lecture euh c’est pas pour moi. » Je voudrais insister là-dessus en mentionnant une étude qui a été faite en 2013 par Alice Sullivan de l’Université de Londres. Cette étude a montré l’immense importance de la lecture. Vous savez certainement qu’il y a plusieurs facteurs qui entre en jeu dans la réussite d’un étudiant. Par exemple, il y a un facteur qui est assez injuste, c’est le niveau de diplôme des parents. On constate, malheureusement, que les étudiants qui ont la chance d’avoir des parents diplômés ont souvent plus de chance de réussite que les autres. Et bien, il faut savoir que le facteur « lecture régulière » est quatre fois plus important dans la réussite que le facteur « niveau de diplôme des parents. » Euh, donc, ce que je conseille vraiment, c’est de se fixer un quart d’heure de lecture par soir. Toujours dans l’objectif d’avoir le courage de s’y mettre, c’est pour un quart d’heure, c’est pas trop long. Évidemment, si, pris dans la lecture on a envie de lire plus, c’est pas grave, c’est très bien. Sinon, si on est fatigué, on se tient vraiment à un quart d’heure, mais un quart d’heure de lecture chaque soir. Alors, ça peut être des livres, peu importe, ce qui vous intéressent, pas trop difficile puisque le but c’est vraiment que vous vous sentiez motivé. Vous allez dans une bibliothèque, une médiathèque et vous dites le type de livre qui vous intéresse a priori, que ça soit roman d’aventure, roman d’amour, roman policier, mais un quart d’heure de lecture par soir. Ça peut même être le journal Équipe, il est bien écrit, mais vous vous en tenez à ce temps de lecture. Autre stratégie pour progresser en français, c’est de vous faire une liste de mots difficiles. Alors, la liste de mots difficiles, eh bien c’est très simple : dès que vous hésitez sur un mot, par exemple, vous avez eu à écrire le mot « développement » et vous avez hésité « il y a un l ? il y a deux p ? » eh bien vous l’écrivez sur votre liste de mots difficiles, et vous relisez régulièrement votre liste de mots difficiles. L’avantage, c’est que cette liste va naturellement compter les mots qui vous viennent le plus facilement sous la plume quand vous écrivez, donc les mots dont vous avez le plus besoin et à force de relire votre liste de mots difficiles, vous allez photographier l’orthographe correcte des mots. Quand on est invité à déjeuner ou à dîner chez des Français, le repas commence normalement avec un apéritif, ou apéro. Avec son choix de boisson et une variété de choses à grignoter, c’est un moment agréable pour bavarder avec les hôtes et les autres invités avant de passer à table. * On peut acheter le vin de noix, vin d’orange et vin de citron, par exemple, dans les magasins de vins, mais beaucoup de nos amis suivent la tradition et font des économies en les fabricant eux-mêmes. Ces vins aux fruits sont, en général, un mélange de vin, alcool de grain, sucre et fruits qu’on a laissé mariner pendant quelques semaines ou mois et qui a une teneur en alcool plus élevée que le vin ordinaire. ** Pas mal de Français semblent croire que les Américains sont fanas de whisky. Une fois, la dame qui nous avait invités à déjeuner chez elle nous a offert, très fièrement, un whisky. Elle nous a raconté l’histoire de son moment de panique en se rendant compte, dans les heures précédant le repas, qu’elle n’en avait pas. Elle a été choquée d’apprendre que mon mari et moi n’aimons pas du tout le whisky. À une autre occasion, lors d’un repas chez nous, l’un des invités nous a offert une bouteille de whisky (que nous avons bien sûr acceptée sans grimacer). Qu’est-ce que la traduction ? C’est la conversion écrite d’une langue, dite la langue « source », en une seconde langue, la langue « cible ». Pour traduire un texte, il faut avoir évidemment une connaissance approfondie des deux langues, mais être bilingue est loin d’être le seul critère. Pour réaliser une bonne traduction, il faut aussi comprendre les cultures rattachées aux langues pour saisir non seulement la signification des mots et expressions, mais aussi l’importance des fêtes, évènements, livres et chansons mentionnés dans le texte. Il est souvent souhaitable d’adapter le texte quand, par exemple, le personnage principal d’un roman déclare que « c’était aussi emballant qu’un match de Coupe du monde ». Pour une audience américaine, on ferait mieux de traduire ce sentiment. Il faut également faire attention aux différences linguistiques. En français, on parle d’une quantité indéfinie importante avec « des dizaines ». Bien que l’on puisse dire tens en anglais, il est beaucoup plus idiomatique de dire dozens, même si le chiffre n’est pas tout à fait le même. Idem pour les expressions idiomatiques. Si la source dit « j’ai un chat dans la gorge », il faut absolument changer l’animal en grenouille pour les Anglophones. Tout aussi important, on doit utiliser des constructions grammaticales convenables à la langue cible. En français, on utilise souvent le futur en décrivant la vie d’un personnage dans une biographie, mais en anglais, le présent ou le conditionnel sont plus appropriés – en apprendre plus. Le principal, c’est non seulement de rester fidèle à la signification des mots, mais de créer un texte dans la langue cible qui se lit comme si c’était l’original. Voilà pourquoi les deux textes ne sont pas identiques : on ne cherche pas une traduction mot-à-mot, mais un texte adapté, voire récrit qui garde et la même signification et le même sentiment que l’original. Quand on habite en France, l’un des meilleurs moyens de rencontrer des gens est de devenir membre d’une association loi de 1901, ce qu’on appellerait en anglais probablement un « club ». Ces associations sont à but non lucratif, et peuvent être déclarées ou pas. Il y a des associations pour tout : pour des sports, des jeux, des activités, des études. Il y a des associations pour les expatriés d’un pays particulier ou pour rassembler tous ceux qui ont autrefois habité dans une certaine région de France. Des associations à but humanitaire luttent pour des individus désavantagés en France ou ailleurs, et des associations créatives réunissent ceux qui aiment danser, chanter ou écrire. Les associations de quartier ou d’arrondissement travaillent pour animer leurs rues, tandis que les associations de tel ou tel festival passent toute l’année à planifier ce seul événement. Il n’est pas toujours facile de trouver une association appropriée. Il y a des annuaires sur internet plus ou moins complets, et on peut toujours demander à l’office de tourisme, mais souvent on découvre une association simplement en parlant avec quelqu’un qui la mentionne. On avait de la chance à Hyères, où on peut obtenir un livret à l’office de tourisme qui répertorie les 300 associations de cette ville de 52 000 habitants. Je recommande l’association Accueil des Villes Françaises pour tout le monde.\"\n",
    "new_df = process_text(input_text, 'B1')\n",
    "\n",
    "new_df = pd.concat([new_df, new_df], ignore_index=True)\n",
    "\n",
    "input_text = \"L’année 1866 fut marquée par un événement bizarre, un phénomène inexpliqué et inexplicable que personne n’a sans doute oublié. Sans parler des rumeurs qui agitaient les populations des ports et surexcitaient l’esprit public à l’intérieur des continents, les gens de mer furent particulièrement émus. Les négociants, armateurs, capitaines de navires, skippers et masters de l’Europe et de l’Amérique, officiers des marines militaires de tous pays, et, après eux, les gouvernements des divers États des deux continents, se préoccupèrent de ce fait au plus haut point. En effet, depuis quelque temps, plusieurs navires s’étaient rencontrés sur mer avec « une chose énorme », un objet long, fusiforme, parfois phosphorescent, infiniment plus vaste et plus rapide qu’une baleine. Les faits relatifs à cette apparition, consignés aux divers livres de bord, s’accordaient assez exactement sur la structure de l’objet ou de l’être en question, la vitesse inouïe de ses mouvements, la puissance surprenante de sa locomotion, la vie particulière dont il semblait doué. Si c’était un cétacé, il surpassait en volume tous ceux que la science avait classés jusqu’alors. Ni Cuvier, ni Lacépède, ni M. Dumeril, ni M. de Quatrefages n’eussent admis l’existence d’un tel monstre—à moins de l’avoir vu, ce qui s’appelle vu de leurs propres yeux de savants. À prendre la moyenne des observations faites à diverses reprises—en rejetant les évaluations timides qui assignaient à cet objet une longueur de deux cents pieds et en repoussant les opinions exagérées qui le disaient large d’un mille et long de trois—on pouvait affirmer, cependant, que cet être phénoménal dépassait de beaucoup toutes les dimensions admises jusqu’à ce jour par les ichtyologistes—s’il existait toutefois. Or, il existait, le fait en lui-même n’était plus niable, et, avec ce penchant qui pousse au merveilleux la cervelle humaine, on comprendra l’émotion produite dans le monde entier par cette surnaturelle apparition. Quant à la rejeter au rang des fables, il fallait y renoncer. Il y avait en Westphalie, dans le château de M. le baron de Thunder-ten-tronckh, un jeune garçon à qui la nature avait donné les mœurs les plus douces. Sa physionomie annonçait son âme. Il avait le jugement assez droit, avec l’esprit le plus simple ; c’est, je crois, pour cette raison qu’on le nommait Candide.* Les anciens domestiques de la maison soupçonnaient qu’il était fils de la sœur de monsieur le baron et d’un bon et honnête gentilhomme du voisinage, que cette demoiselle ne voulut jamais épouser parce qu’il n’avait pu prouver que soixante et onze quartiers, et que le reste de son arbre généalogique avait été perdu par l’injure du temps. Monsieur le baron était un des plus puissants seigneurs de la Westphalie, car son château avait une porte et des fenêtres. Sa grande salle même était ornée d’une tapisserie. Tous les chiens de ses basses-cours composaient une meute dans le besoin ; ses palefreniers étaient ses piqueurs ; le vicaire du village était son grand aumônier. Ils l’appelaient tous monseigneur, et ils riaient quand il faisait des contes. Madame la baronne, qui pesait environ trois cent cinquante livres, s’attirait par là une très grande considération, et faisait les honneurs de la maison avec une dignité qui la rendait encore plus respectable. Sa fille Cunégonde, âgée de dix-sept ans, était haute en couleur, fraîche, grasse, appétissante. Le fils du baron paraissait en tout digne de son père. Le précepteur Pangloss était l’oracle de la maison, et le petit Candide écoutait ses leçons avec toute la bonne foi de son âge et de son caractère. Pangloss enseignait la métaphysico-théologo-cosmolonigologie. Il prouvait admirablement qu’il n’y a point d’effet sans cause, et que, dans ce meilleur des mondes possibles, le château de monseigneur le baron était le plus beau des châteaux et madame la meilleure des baronnes possibles. « Il est démontré, disait-il, que les choses ne peuvent être autrement : car, tout étant fait pour une fin, tout est nécessairement pour la meilleure fin. Remarquez bien que les nez ont été faits pour porter des lunettes, aussi avons-nous des lunettes. Les jambes sont visiblement instituées pour être chaussées, et nous avons des chausses. Les pierres ont été formées pour être taillées, et pour en faire des châteaux, aussi monseigneur a un très beau château ; le plus grand baron de la province doit être le mieux logé ; et, les cochons étant faits pour être mangés, nous mangeons du porc toute l’année : par conséquent, ceux qui ont avancé que tout est bien ont dit une sottise ; il fallait dire que tout est au mieux. » Candide écoutait attentivement, et croyait innocemment; car il trouvait Mlle Cunégonde extrêmement belle, quoiqu’il ne prît jamais la hardiesse de le lui dire. Il concluait qu’après le bonheur d’être né baron de Thunder-ten-tronckh, le second degré de bonheur était d’être Mlle Cunégonde ; le troisième, de la voir tous les jours ; et le quatrième, d’entendre maître Pangloss, le plus grand philosophe de la province, et par conséquent de toute la terre. Un jour, Cunégonde, en se promenant auprès du château, dans le petit bois qu’on appelait parc, vit entre des broussailles le docteur Pangloss qui donnait une leçon de physique expérimentale à la femme de chambre de sa mère, petite brune très jolie et très docile. Comme Mlle Cunégonde avait beaucoup de dispositions pour les sciences, elle observa, sans souffler, les expériences réitérées dont elle fut témoin ; elle vit clairement la raison suffisante du docteur, les effets et les causes, et s’en retourna tout agitée, toute pensive, toute remplie du désir d’être savante, songeant qu’elle pourrait bien être la raison suffisante du jeune Candide, qui pouvait aussi être la sienne. Elle rencontra Candide en revenant au château, et rougit ; Candide rougit aussi ; elle lui dit bonjour d’une voix entrecoupée, et Candide lui parla sans savoir ce qu’il disait. Le lendemain après le dîner, comme on sortait de table, Cunégonde et Candide se trouvèrent derrière un paravent ; Cunégonde laissa tomber son mouchoir, Candide le ramassa, elle lui prit innocemment la main, le jeune homme baisa innocemment la main de la jeune demoiselle avec une vivacité, une sensibilité, une grâce toute particulière ; leurs bouches se rencontrèrent, leurs yeux s’enflammèrent, leurs genoux tremblèrent, leurs mains s’égarèrent. M. le baron de Thunder-ten-tronckh passa auprès du paravent, et voyant cette cause et cet effet, chassa Candide du château à grands coups de pied dans le derrière ; Cunégonde s’évanouit ; elle fut souffletée par Madame la Baronne dès qu’elle fut revenue à elle-même ; et tout fut consterné dans le plus beau et le plus agréable des châteaux possibles. Tout est bien, sortant des mains de l’Auteur des choses ; tout dégénere entre les mains de l’homme. Il force une terre à nourrir les productions d’une autre, un arbre à porter les fruits d’un autre ; il mêle et confond les climats, les éléments, les saisons ; il mutile son chien, son cheval, son esclave ; il bouleverse tout, il défigure tout, il aime la difformité, les monstres ; il ne veut rien tel que l’a fait la nature, pas même l’homme ; il le faut dresser pour lui, comme un cheval de manége ; il le faut contourner à sa mode, comme un arbre de son jardin. Sans cela, tout irait plus mal encore, et notre espèce ne veut pas être façonnée à demi. Dans l’état où sont désormais les choses, un homme abandonné dès sa naissance à lui-même parmi les autres serait le plus défiguré de tous. Les préjugés, l’autorité, la nécessité, l’exemple, toutes les institutions sociales, dans lesquelles nous nous trouvons submergés, étoufferaient en lui la nature, et ne mettraient rien à la place. Elle y serait comme un arbrisseau que le hasard fait naître au milieu d’un chemin, et que les passants font bientôt périr, en le heurtant de toutes parts et le pliant dans tous les sens. C’est à toi que je m’adresse, tendre et prévoyante mère, qui sus t’écarter de la grande route, et garantir l’arbrisseau naissant du choc des opinions humaines ! Cultive, arrose la jeune plante avant qu’elle meure : ses fruits feront un jour tes délices. Forme de bonne heure une enceinte autour de l’âme de ton enfant ; un autre en peut marquer le circuit, mais toi seule y dois poser la barrière. \"\n",
    "new_df = process_text(input_text, 'B2')\n",
    "\n",
    "new_df = pd.concat([new_df, new_df], ignore_index=True)\n",
    "\n",
    "input_text = \"En 1815, M. Charles-François-Bienvenu Myriel était évêque de Digne. C’était un vieillard d’environ soixante-quinze ans ; il occupait le siège de Digne depuis 1806. Quoique ce détail ne touche en aucune manière au fond même de ce que nous avons à raconter, il n’est peut-être pas inutile, ne fût-ce que pour être exact en tout, d’indiquer ici les bruits et les propos qui avaient couru sur son compte au moment où il était arrivé dans le diocèse. Vrai ou faux, ce qu’on dit des hommes tient souvent autant de place dans leur vie et surtout dans leur destinée que ce qu’ils font. M. Myriel était fils d’un conseiller au parlement d’Aix ; noblesse de robe. On contait de lui que son père, le réservant pour hériter de sa charge, l’avait marié de fort bonne heure, à dix-huit ou vingt ans, suivant un usage assez répandu dans les familles parlementaires. Charles Myriel, nonobstant ce mariage, avait, disait-on, beaucoup fait parler de lui. Il était bien fait de sa personne, quoique d’assez petite taille, élégant, gracieux, spirituel ; toute la première partie de sa vie avait été donnée au monde et aux galanteries. La révolution survint, les événements se précipitèrent, les familles parlementaires décimées, chassées, traquées, se dispersèrent. M. Charles Myriel, dès les premiers jours de la révolution, émigra en Italie. Sa femme y mourut d’une maladie de poitrine dont elle était atteinte depuis longtemps. Ils n’avaient point d’enfants. Que se passa-t-il ensuite dans la destinée de M. Myriel ? L’écroulement de l’ancienne société française, la chute de sa propre famille, les tragiques spectacles de 93, plus effrayants encore peut-être pour les émigrés qui les voyaient de loin avec le grossissement de l’épouvante, firent-ils germer en lui des idées de renoncement et de solitude ? Fut-il, au milieu d’une de ces distractions et de ces affections qui occupaient sa vie, subitement atteint d’un de ces coups mystérieux et terribles qui viennent quelquefois renverser, en le frappant au cœur, l’homme que les catastrophes publiques n’ébranleraient pas en le frappant dans son existence et dans sa fortune ? Nul n’aurait pu le dire ; tout ce qu’on savait, c’est que, lorsqu’il revint d’Italie, il était prêtre. Vers l’époque du couronnement, une petite affaire de sa cure, on ne sait plus trop quoi, l’amena à Paris. Entre autres personnes puissantes, il alla solliciter pour ses paroissiens M. le cardinal Fesch. Un jour que l’empereur était venu faire visite à son oncle, le digne curé, qui attendait dans l’antichambre, se trouva sur le passage de sa majesté. Napoléon, se voyant regardé avec une certaine curiosité par ce vieillard, se retourna, et dit brusquement: L’empereur, le soir même, demanda au cardinal le nom de ce curé, et quelque temps après M. Myriel fut tout surpris d’apprendre qu’il était nommé évêque de Digne. M. Myriel devait subir le sort de tout nouveau venu dans une petite ville où il y a beaucoup de bouches qui parlent et fort peu de têtes qui pensent. Il devait le subir, quoiqu’il fût évêque et parce qu’il était évêque. Mais, après tout, les propos auxquels on mêlait son nom n’étaient peut-être que des propos ; du bruit, des mots, des paroles ; moins que des paroles, des « palabres », comme dit l’énergique langue du midi. Nous étions à l’Étude, quand le Proviseur entra, suivi d’un nouveau habillé en bourgeois et d’un garçon de classe qui portait un grand pupitre. Ceux qui dormaient se réveillèrent, et chacun se leva comme surpris dans son travail. — Monsieur Roger, lui dit-il à demi-voix, voici un élève que je vous recommande, il entre en cinquième.* Si son travail et sa conduite sont méritoires, il passera dans les grands, où l’appelle son âge. Resté dans l’angle, derrière la porte, si bien qu’on l’apercevait à peine, le nouveau était un gars de la campagne, d’une quinzaine d’années environ, et plus haut de taille qu’aucun de nous tous. Il avait les cheveux coupés droit sur le front, comme un chantre de village, l’air raisonnable et fort embarrassé. Quoiqu’il ne fût pas large des épaules, son habit-veste de drap vert à boutons noirs devait le gêner aux entournures et laissait voir, par la fente des parements, des poignets rouges habitués à être nus. Ses jambes, en bas bleus, sortaient d’un pantalon jaunâtre très tiré par les bretelles. Il était chaussé de souliers forts, mal cirés, garnis de clous. Mais, soit qu’il n’eût pas remarqué cette manœuvre ou qu’il n’eut osé s’y soumettre, la prière était finie que le nouveau tenait encore sa casquette sur ses deux genoux. C’était une de ces coiffures d’ordre composite, où l’on retrouve les éléments du bonnet à poil, du chapska, du chapeau rond, de la casquette de loutre et du bonnet de coton, une de ces pauvres choses, enfin, dont la laideur muette a des profondeurs d’expression comme le visage d’un imbécile. Ovoïde et renflée de baleines, elle commençait par trois boudins circulaires ; puis s’alternaient, séparés par une bande rouge, des losanges de velours et de poils de lapin ; venait ensuite une façon de sac qui se terminait par un polygone cartonné, couvert d’une broderie en soutache compliquée, et d’où pendait, au bout d’un long cordon trop mince, un petit croisillon de fils d’or, en manière de gland. Elle était neuve ; la visière brillait. Nous avions l’habitude, en entrant en classe, de jeter nos casquettes par terre, afin d’avoir ensuite nos mains plus libres ; il fallait, dès le seuil de la porte, les lancer sous le banc, de façon à frapper contre la muraille en faisant beaucoup de poussière ; c’était là le genre. On commença la récitation des leçons. Il les écouta de toutes ses oreilles, attentif comme au sermon, n’osant même croiser les cuisses, ni s’appuyer sur le coude, et, à deux heures, quand la cloche sonna, le maître d’études fut obligé de l’avertir, pour qu’il se mît avec nous dans les rangs. Quoi qu’il en fût, après neuf ans d’épiscopat et de résidence à Digne, tous ces racontages, sujets de conversation qui occupent dans le premier moment les petites villes et les petites gens, étaient tombés dans un oubli profond. Personne n’eût osé en parler, personne n’eût même osé s’en souvenir. M. Myriel était arrivé à Digne accompagné d’une vieille fille, mademoiselle Baptistine, qui était sa sœur et qui avait dix ans de moins que lui. Ils avaient pour tout domestique une servante du même âge que mademoiselle Baptistine, et appelée madame Magloire, laquelle, après avoir été « la servante de M. le Curé », prenait maintenant le double titre de femme de chambre de mademoiselle et femme de charge de monseigneur. Mademoiselle Baptistine était une personne longue, pâle, mince, douce ; elle réalisait l’idéal de ce qu’exprime le mot « respectable » ; car il semble qu’il soit nécessaire qu’une femme soit mère pour être vénérable. Elle n’avait jamais été jolie ; toute sa vie, qui n’avait été qu’une suite de saintes œuvres, avait fini par mettre sur elle une sorte de blancheur et de clarté ; et, en vieillissant, elle avait gagné ce qu’on pourrait appeler la beauté de la bonté. Ce qui avait été de la maigreur dans sa jeunesse était devenu, dans sa maturité, de la transparence ; et cette diaphanéité laissait voir l’ange. C’était une âme plus encore que ce n’était une vierge. Sa personne semblait faite d’ombre ; à peine assez de corps pour qu’il y eût là un sexe ; un peu de matière contenant une lueur ; de grands yeux toujours baissés ; un prétexte pour qu’une âme reste sur la terre. Madame Magloire était une petite vieille, blanche, grasse, replète, affairée, toujours haletante, à cause de son activité d’abord, ensuite à cause d’un asthme. À son arrivée, on installa M. Myriel en son palais épiscopal avec les honneurs voulus par les décrets impériaux qui classent l’évêque immédiatement après le maréchal de camp. Le maire et le président lui firent la première visite, et lui de son côté fit la première visite au général et au préfet. L’installation terminée, la ville attendit son évêque à l’œuvre.\"\n",
    "new_df = process_text(input_text, 'C1')\n",
    "\n",
    "new_df = pd.concat([new_df, new_df], ignore_index=True)\n",
    "\n",
    "input_text = \"la liste des produits alternatifs qui visent à « faire aimer » autant qu’à « faire réviser» est longue. Pour éviter d’oublier en deux mois des compétences si chèrement apprises durant l’année, mais aussi pour se cultiver ! Que restera-t-il à la rentrée des acquis de l’année scolaire ? Cerveau et seau de plage jouent-ils les vases communicants Concentrés toute l’année sur les résultats scolaires de leurs enfants, les parents ne sont pas prêts à laisser les bains de mer ou de soleil délaver les tables de multiplication, les plus-que-parfait de l’indicatif et autres théorèmes de géométrie si chèrement acquis. Pour conjurer les deux mois de vacances, ils achètent donc leur potion en librairie pour un investissement moyen de 7 euros. Cela s’appelle cahier de vacances, et 4,5 millions d’écoliers et d’élèves n’ont d’autre solution que de lui trouver une place dans leur valise. Après, c’est une autre affaire. A tel point que, parmi les parents qui ont investi dans ces produits, 4,4 % déclarent que leur enfant ne l’a jamais ouvert… et 72,2 % qu’il ne l’a utilisé qu’en partie. Des chiffres tirés d’une des rares enquêtes sur le sujet, réalisée en 2000 (publiée en 2001) par l’Institut de recherche sur l’économie de l’édu- cation (Irédu) auprès des parents de 2 500 enfants de l’académie de Dijon (Côte-d’Or). Qu’est-ce qui peut bien poser problème dans ces petits livrets pourtant plutôt attractifs pour que seuls 23,4 % de leurs détenteurs arrivent au bout ? Jeune retraité de l’éducation nationale, Roger Rougier a sa réponse. « Je les ai subis, et je les ai fait subir à mes enfants, jusqu’à ce que j’ose m’en affranchir, résume cet inventeur de produits plus ludiques. Je les ai abandonnés le jour où j’ai commencé à faire tenir des cahiers d’été à mes enfants et à créer des jeux avec eux. Je me souviens d’un été durant lequel nous nous étions beaucoup déplacés en caravane. En quittant chaque étape, mes enfants  dessinaient le lieu ou une personne qu’ils y avaient  rencontrée. A la fin des vacances, nous avons assem-  blé ces vignettes et créé ensemble un jeu de l’oie.  Comme support d’échange, ça a été fantastique. Nous  ne pouvions pas faire une partie sans que l’un d’eux  ne raconte un épisode ou un personnage », rappelle  celui qui, ni vu ni connu, a fait, par ce biais,  travailler la narration à ses enfants.  Jouer sur le ludique  Fort de ce succès, Roger Rougier a continué à  développer cette approche amusante des appren-  tissages. Très vite, il s’est mis à créer des fiches de  logique. « Je l’ai fait pour ma classe parce que les  enfants aiment raisonner, que cela les met en  confiance et qu’ensuite ils sont disponibles pour une  leçon », se souvient-il. Ce qui est étonnant, c’est  que les énigmes et les problèmes conçus pour la  classe régalent aussi les petits vacanciers. Expli-  cation de l’auteur : « Ce sont des jeux qui obligent  à une réflexion, un travail intellectuel ; mais l’idée de  jeu masque le côté labeur ». Vendus sous forme de  petits formats noir et blanc, ses Jeux pour s’entraîner    Faut-il enseigner l’informatique à l’école primaire ? Et comment ?  La question n’est plus de savoir s’il faut apprendre l’informatique et son langage, mais de savoir comment,  pour quels usages, et à quelle étape du cursus le faire. […]  DOSSIER  Lisez les documents suivants.  BÂTIR L’ÉCOLE DU XXIe SIÈCLE  Un curseur qu’on a du mal à placer  L’apprentissage du code et plus largement d’une culture générale du numérique à l’école est une mesure récla-  mée depuis longtemps par l’Académie des sciences, soutenue par des acteurs qui comptent dans le secteur  numérique. […] Selon un sondage publié en mai dernier par BVA (société française de sondages) et le Syntec  Numérique (fédération professionnelle du secteur informatique) favorable à la mesure, 87 % des Français  seraient même d’accord pour que la programmation informatique soient enseignée à l’école (24 % à partir du  primaire, 41 % à partir du collège).  Mais cette initiative suscite par ailleurs beaucoup de réticences. On entend souvent l’argument selon lequel  on n’a pas besoin de connaître la mécanique pour apprendre à conduire. Le nombre insuffisant de professeurs  formés est également un frein pour beaucoup d’adversaires de cette mesure, qui la jugent inapplicable.  Entre ceux qui ne jurent que par l’introduction de l’informatique dans l’enseignement obligatoire, et ceux qui  ont peur que l’on veuille transformer le primaire en une grande école d’informatique, il existe pourtant des  pistes pour initier les enseignants et favoriser un passage du périscolaire au scolaire, sans avoir à attendre une  réforme du socle commun* qui prendra des années. L’action de la fondation La Main à la pâte, qui œuvre de-  puis près de 20 ans pour enseigner la science différemment à l’école, est un exemple dont on pourrait s’inspirer.  La Main à la pâte, au service de la science à l’école depuis 20 ans  La Fondation La Main à la pâte a été créée en 2011, dans la continuité de l’opération du même nom lancée en  1995 par l’Académie des sciences à l’initiative du prix Nobel de physique, Georges Charpak. Cette action avait  pour objectif, dès l’origine, d’aider les professeurs à enseigner la science et la technologie en mettant en œuvre  une pédagogie privilégiant l’expérimentation, la discussion, une pratique active et collective. L’idée était de  stimuler chez les élèves l’esprit scientifique et les capacités d’expression, de favoriser leur compréhension du  monde, et de leur permettre de mieux jouer leur rôle de citoyen en proposant des projets pédagogiques orientés  vers des questions de société (éducation à la santé, au développement durable...). Chacun de ces projets touche  en moyenne 10 000 classes. Un beau succès.  Une des originalités de la fondation est d’impliquer la communauté scientifique dans la création des ressources  pédagogiques, l’accompagnement des classes et la formation continue des enseignants. « Ce qui n’a l’air de  rien mais constituait une véritable révolution de palais à l’époque, au ministère de l’éducation nationale »,  confie David Wilgenbus, responsable du secteur production de ressources à La Main à la pâte.  Un enseignement fondé sur l’expérimentation et la pratique, des objectifs d’apprentissage transversaux, des  actions tournées en priorité vers la formation continue des enseignants, menées en collaboration avec la com-  munauté scientifique et professionnelle : le travail de défrichage réalisé par la fondation dans le domaine des  sciences pourrait s’appliquer parfaitement à la problématique de l’enseignement de la culture informatique. décérébrés prenant la place des ouvriers dans les usines. Il vient de la racine slave « robota » qui signifie travail  de force. De là sont nés deux mythes : le robot est un humanoïde et le robot va prendre la place de l’homme.  En parallèle, les romans et les films de science-fiction ont présenté des robots, comme les « Transformers »  par exemple, aux pouvoirs surhumains. La fascination/répulsion des robots vient du respect qu’ils inspirent  pour exécuter des tâches pénibles et nous simplifier la vie, mais qui se mêle à la crainte de les voir prendre le  contrôle de nos vies. J’ai identifié trois peurs fondamentales du robot : la crainte instinctive du métal contre la  chair, la crainte sociétale, presque désespérée du robot qui va voler le travail de l’homme, et, enfin, la crainte  identitaire de voir le robot nous dépasser en capacités intellectuelles ou autres. Il faut juste toujours se rappeler  qu’ils sont avant tout machines savantes et que l’imagination des auteurs est sans limite. Le train, en son temps,  était également craint… […]  Aujourd’hui ou demain, des robots seront-ils capables de remplacer les hommes au travail ? Devien-  dront-ils les esclaves de la société postindustrielle ? Quelles tâches pourraient-ils accomplir ? […]  Bruno Bonnell : Il n’y a aucune tâche que les robots ne sauront pas, un jour, exécuter, de la plus fastidieuse  à la plus méticuleuse, de la plus répétitive à la plus sophistiquée. Qui aurait pensé qu’un jour les enfants de  dix ans pouvaient avoir le monde dans leurs poches au bout d’un portable ? Les véhicules seront autonomes,  plus besoin de chauffeurs, les opérations chirurgicales seront robotisées, les mines seront exploitées par des  robots… Mais utiliser le mot esclave revient à considérer qu’ils sont autre chose que des machines. Leurs  capacités de déduction et de connexion sont certes développées, leur force mécanique est puissante, leur préci-  sion micrométrique, mais les robots restent des machines au service de l’homme. Certains métiers vont dispa-  raître, mais d’autres apparaître. Le maréchal-ferrant et le cocher ont dû se reconvertir. À son essor, l’industrie  de l’automobile a créé beaucoup plus d’emplois qu’elle n’en a supprimés. Il est important d’anticiper cette  « robolution » et de former les gens à des métiers d’avenir pour l’accompagner, sans drame social.  Brigitte Munier : […] L’image d’un robot esclave n’est pas neuve ! Mais on peut aussi imaginer un robot allié  ou compagnon, voire amant. Machine intelligente (capable d’apprentissage), utilisée déjà dans le contexte des  loisirs, de l’éducation, de la médecine, de la police, de l’armée, de la conquête spatiale, etc., le robot est voué  à exécuter toutes les tâches pour lesquelles on voudra, ou pourra, le programmer  \"\n",
    "new_df = process_text(input_text, 'C2')\n",
    "\n",
    "new_df = pd.concat([new_df, new_df], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5144\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data_pd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go Camembert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\mooli\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=os.environ.get(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert/camembert-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'roberta.embeddings.word_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import accelerate\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import Dataset, load_metric\n",
    "import logging\n",
    "from transformers import DataCollatorWithPadding, DataCollatorForTokenClassification, BitsAndBytesConfig\n",
    "from accelerate.utils import BnbQuantizationConfig\n",
    "from accelerate.utils import load_and_quantize_model\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert/camembert-large',do_lower_case=True)\n",
    "\n",
    "def encode_data(tokenizer, df):\n",
    "    texts = df['sentence'].tolist()\n",
    "    #labels = df['difficulty'].map({'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}).tolist()\n",
    "    labels = df['difficulty'].map({'A1': 0, 'A2': 1, 'B1': 2, 'B2': 3, 'C1': 4, 'C2': 5}).tolist()\n",
    "    #label_encoder = LabelEncoder()\n",
    "    #labels = label_encoder.fit_transform(labels)\n",
    "    encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=128)\n",
    "    return Dataset.from_dict({\n",
    "        'input_ids': encodings['input_ids'],\n",
    "        'attention_mask': encodings['attention_mask'],\n",
    "        'labels': labels\n",
    "    })\n",
    "\n",
    "train_data, val_data = train_test_split(training_data_pd, test_size=0.1, random_state=42)\n",
    "\n",
    "#train_data = pd.concat([train_data, new_df], ignore_index=True)\n",
    "\n",
    "'''\n",
    "#shuffle\n",
    "train_data = pd.concat([train_data, train_data], ignore_index=True)\n",
    "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "'''\n",
    "\n",
    "train_dataset = encode_data(tokenizer, train_data)\n",
    "val_dataset = encode_data(tokenizer, val_data)\n",
    "\n",
    "model = CamembertForSequenceClassification.from_pretrained('camembert/camembert-large', num_labels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 2, 5, 0, 5, 1, 3, 1, 3, 1, 5, 4, 4, 4, 5, 1, 4, 1, 2, 2, 4, 5, 1, 0, 1, 2, 0, 2, 4, 5, 0, 3, 0, 3, 1, 4, 1, 2, 5, 5, 0, 1, 3, 4, 4, 5, 1, 4, 1, 5, 3, 1, 0, 5, 5, 0, 5, 2, 5, 2, 2, 3, 5, 2, 4, 2, 0, 3, 4, 1, 0, 3, 3, 1, 0, 0, 2, 0, 1, 4, 4, 3, 1, 2, 4, 1, 5, 2, 1, 4, 4, 2, 3, 4, 4, 3, 3, 0, 1, 5, 3, 5, 1, 2, 4, 5, 3, 4, 5, 3, 4, 2, 1, 5, 1, 1, 3, 5, 3, 2, 3, 1, 4, 4, 5, 4, 0, 4, 3, 1, 5, 3, 1, 0, 1, 5, 4, 1, 0, 4, 0, 2, 4, 1, 1, 4, 5, 5, 5, 0, 2, 4, 3, 4, 3, 5, 5, 4, 3, 0, 3, 4, 1, 2, 1, 1, 5, 1, 1, 3, 1, 4, 3, 3, 1, 4, 1, 4, 2, 4, 0, 0, 3, 5, 3, 0, 5, 3, 1, 4, 0, 4, 3, 2, 5, 0, 2, 0, 3, 5, 5, 3, 0, 4, 3, 2, 1, 0, 1, 5, 3, 2, 2, 3, 4, 1, 3, 3, 0, 1, 2, 4, 4, 5, 2, 0, 3, 1, 5, 2, 5, 2, 3, 3, 4, 5, 4, 3, 3, 4, 2, 5, 1, 4, 3, 4, 5, 4, 3, 2, 3, 1, 4, 1, 5, 3, 1, 5, 1, 2, 3, 4, 0, 3, 2, 4, 0, 0, 1, 1, 0, 5, 2, 0, 5, 2, 2, 0, 1, 2, 3, 4, 3, 1, 0, 3, 4, 2, 1, 3, 0, 1, 3, 2, 5, 0, 5, 0, 5, 1, 5, 5, 1, 2, 1, 5, 3, 2, 2, 0, 4, 5, 1, 3, 1, 3, 0, 5, 0, 4, 0, 2, 3, 2, 0, 2, 0, 2, 4, 5, 2, 2, 5, 4, 2, 0, 5, 5, 4, 1, 3, 3, 3, 2, 1, 0, 5, 4, 2, 0, 1, 1, 2, 0, 1, 3, 0, 5, 0, 3, 4, 2, 2, 2, 3, 1, 1, 5, 1, 0, 4, 3, 5, 2, 4, 3, 1, 2, 5, 1, 1, 2, 3, 0, 3, 3, 1, 0, 0, 3, 2, 3, 0, 3, 2, 4, 1, 0, 3, 1, 0, 0, 2, 0, 4, 4, 2, 1, 2, 5, 4, 1, 1, 3, 2, 1, 3, 2, 4, 1, 5, 2, 0, 3, 4, 4, 5, 5, 3, 0, 5, 2, 0, 4, 1, 2, 5, 0, 5, 4, 0, 3, 0, 5, 1, 0, 2, 1, 4, 2, 5, 4, 1, 0, 5, 0, 5, 0, 1, 0, 4, 5, 5, 4, 3, 5, 2, 0, 0, 5, 4, 3, 4, 2, 1, 5, 3, 4, 4, 1, 1, 0, 5, 0, 1, 3, 2, 4, 2, 3, 3, 5, 1, 0, 3, 1, 4, 0, 1, 0, 4, 1, 3, 3, 5, 1, 4, 3, 3, 2, 5, 3, 1, 1, 2, 1, 3, 5, 5, 1, 0, 0, 5, 1, 2, 2, 3, 2, 1, 5, 0, 0, 2, 0, 2, 3, 1, 4, 1, 2, 4, 1, 0, 0, 5, 4, 1, 0, 4, 2, 3, 5, 5, 1, 2, 3, 4, 2, 0, 0, 3, 2, 3, 0, 3, 5, 4, 2, 5, 4, 3, 1, 2, 1, 0, 0, 0, 2, 5, 4, 4, 2, 4, 3, 2, 2, 0, 0, 0, 3, 2, 0, 0, 3, 4, 0, 1, 2, 1, 5, 5, 4, 1, 0, 5, 5, 2, 1, 3, 3, 0, 2, 0, 2, 0, 1, 2, 1, 5, 1, 5, 3, 2, 5, 5, 1, 4, 5, 5, 4, 2, 3, 2, 2, 2, 0, 2, 3, 1, 0, 0, 2, 5, 0, 5, 4, 5, 4, 3, 0, 4, 2, 1, 3, 5, 2, 3, 0, 2, 2, 3, 4, 2, 0, 4, 4, 3, 5, 4, 4, 0, 1, 2, 4, 3, 1, 1, 4, 4, 0, 5, 3, 3, 5, 5, 2, 2, 3, 2, 0, 4, 3, 5, 2, 4, 1, 5, 0, 2, 3, 1, 2, 4, 4, 5, 2, 5, 5, 5, 1, 3, 1, 5, 1, 4, 4, 0, 3, 0, 4, 5, 3, 1, 2, 3, 1, 1, 2, 0, 5, 2, 0, 5, 5, 5, 3, 1, 0, 4, 5, 3, 2, 1, 0, 1, 0, 3, 2, 5, 4, 4, 4, 1, 1, 0, 5, 5, 2, 4, 4, 0, 3, 3, 2, 1, 2, 3, 3, 4, 1, 4, 5, 0, 3, 0, 3, 4, 4, 1, 0, 1, 4, 5, 4, 4, 5, 1, 5, 2, 4, 5, 3, 3, 5, 3, 5, 0, 1, 0, 3, 0, 0, 2, 0, 2, 0, 0, 4, 2, 4, 2, 5, 3, 3, 2, 0, 0, 3, 4, 2, 4, 4, 0, 5, 0, 2, 4, 5, 3, 3, 0, 5, 3, 1, 2, 5, 2, 5, 5, 3, 3, 4, 5, 1, 3, 2, 4, 2, 1, 1, 4, 1, 5, 2, 0, 3, 0, 3, 4, 4, 1, 4, 1, 0, 0, 5, 4, 3, 5, 0, 4, 5, 3, 3, 5, 5, 4, 5, 4, 0, 2, 4, 0, 4, 3, 3, 4, 1, 1, 4, 5, 5, 1, 3, 2, 2, 4, 4, 3, 0, 2, 3, 0, 3, 3, 3, 2, 5, 5, 1, 5, 1, 3, 0, 4, 1, 3, 1, 4, 1, 0, 0, 4, 5, 1, 3, 0, 2, 1, 1, 2, 5, 1, 5, 4, 4, 5, 1, 5, 1, 1, 2, 3, 3, 2, 1, 2, 3, 4, 4, 3, 0, 3, 5, 4, 4, 0, 1, 0, 4, 2, 4, 4, 5, 0, 1, 3, 3, 5, 2, 3, 5, 4, 5, 4, 5, 2, 5, 3, 1, 2, 0, 0, 5, 3, 2, 0, 1, 3, 5, 1, 3, 0, 4, 0, 1, 2, 0, 2, 0, 0, 5, 5, 5, 3, 3, 2, 1, 2, 2, 1, 5, 5, 1, 2, 0, 2, 0, 0, 3, 2, 5, 2, 4, 4, 2, 5, 2, 3, 4, 3, 1, 0, 4, 5, 1, 3, 3, 2, 4, 2, 5, 5, 5, 2, 1, 4, 1, 1, 0, 1, 5, 4, 4, 2, 0, 1, 0, 0, 5, 3, 5, 2, 4, 0, 5, 3, 1, 1, 3, 0, 1, 0, 5, 2, 1, 3, 4, 2, 2, 3, 1, 3, 4, 2, 2, 4, 0, 3, 1, 0, 3, 2, 0, 0, 1, 5, 4, 4, 5, 1, 0, 1, 3, 1, 3, 0, 1, 3, 4, 5, 0, 5, 2, 4, 5, 1, 5, 5, 1, 2, 4, 3, 2, 4, 1, 2, 0, 3, 4, 1, 0, 5, 0, 5, 1, 3, 5, 5, 2, 2, 5, 0, 3, 5, 4, 2, 3, 3, 0, 1, 0, 2, 1, 4, 2, 4, 2, 5, 0, 3, 5, 4, 0, 5, 2, 1, 0, 0, 1, 2, 3, 5, 2, 5, 1, 5, 0, 3, 1, 1, 4, 4, 2, 3, 5, 2, 4, 5, 3, 5, 1, 1, 1, 0, 5, 5, 3, 5, 5, 3, 1, 0, 1, 3, 0, 4, 1, 1, 5, 2, 5, 4, 4, 2, 2, 2, 0, 3, 0, 5, 0, 0, 1, 5, 3, 5, 1, 0, 1, 4, 2, 3, 3, 0, 1, 5, 0, 4, 1, 3, 0, 0, 3, 4, 1, 5, 5, 5, 4, 5, 4, 5, 5, 5, 1, 2, 3, 5, 4, 5, 1, 4, 0, 4, 2, 5, 3, 1, 1, 1, 2, 0, 5, 5, 0, 2, 0, 3, 1, 4, 4, 4, 5, 0, 0, 0, 2, 4, 0, 4, 1, 5, 4, 3, 2, 3, 3, 0, 4, 4, 0, 5, 5, 0, 1, 4, 2, 5, 3, 5, 5, 5, 5, 0, 1, 4, 2, 4, 0, 4, 4, 1, 4, 1, 0, 3, 5, 2, 4, 0, 3, 2, 2, 5, 1, 3, 3, 1, 1, 5, 4, 2, 5, 1, 5, 4, 4, 1, 2, 3, 2, 0, 2, 4, 4, 3, 0, 4, 4, 3, 5, 4, 0, 0, 0, 5, 5, 0, 1, 2, 2, 5, 3, 5, 4, 1, 3, 1, 1, 1, 2, 3, 2, 1, 2, 5, 3, 2, 3, 1, 2, 1, 2, 1, 1, 4, 1, 4, 1, 1, 0, 1, 2, 5, 2, 1, 4, 0, 4, 4, 4, 5, 3, 1, 0, 3, 0, 5, 4, 4, 2, 3, 2, 4, 4, 5, 2, 5, 0, 2, 4, 3, 4, 1, 5, 3, 2, 5, 5, 3, 3, 0, 1, 5, 2, 0, 0, 1, 0, 1, 2, 3, 3, 0, 2, 0, 4, 4, 2, 2, 4, 1, 2, 3, 4, 1, 1, 3, 0, 1, 1, 4, 4, 5, 4, 0, 0, 0, 2, 2, 3, 0, 4, 4, 5, 1, 5, 5, 2, 5, 0, 5, 2, 4, 1, 0, 1, 1, 0, 1, 3, 3, 5, 5, 4, 4, 3, 4, 2, 4, 4, 0, 2, 1, 0, 1, 1, 3, 2, 3, 4, 1, 0, 5, 5, 3, 4, 5, 4, 1, 0, 1, 0, 3, 3, 3, 0, 2, 0, 0, 2, 4, 5, 4, 0, 0, 1, 4, 0, 0, 4, 5, 3, 0, 1, 3, 3, 2, 3, 0, 5, 2, 4, 3, 4, 2, 2, 2, 4, 3, 3, 5, 2, 5, 3, 2, 1, 0, 0, 4, 2, 2, 3, 5, 1, 2, 0, 4, 2, 3, 5, 2, 0, 5, 5, 3, 0, 0, 4, 5, 4, 2, 2, 0, 2, 1, 1, 2, 2, 0, 2, 0, 0, 3, 0, 4, 3, 2, 2, 3, 5, 0, 5, 1, 3, 3, 3, 3, 0, 4, 0, 4, 5, 1, 3, 4, 1, 3, 3, 0, 2, 1, 5, 2, 0, 4, 2, 4, 0, 3, 3, 2, 2, 1, 3, 2, 2, 3, 0, 3, 5, 5, 2, 5, 5, 3, 1, 3, 5, 4, 5, 0, 1, 3, 4, 0, 0, 4, 5, 1, 0, 2, 1, 5, 1, 4, 0, 4, 0, 1, 3, 1, 2, 0, 4, 1, 1, 5, 2, 1, 4, 5, 1, 2, 0, 5, 1, 4, 0, 1, 2, 2, 5, 2, 0, 2, 3, 4, 3, 4, 2, 3, 3, 4, 2, 4, 4, 4, 0, 5, 4, 2, 2, 1, 1, 3, 2, 3, 4, 0, 0, 1, 5, 0, 0, 0, 4, 3, 1, 4, 2, 4, 3, 4, 5, 5, 2, 4, 0, 4, 1, 3, 5, 4, 2, 3, 4, 0, 0, 2, 0, 1, 4, 4, 0, 3, 0, 3, 4, 5, 5, 0, 3, 5, 3, 1, 2, 0, 0, 3, 2, 5, 0, 1, 1, 1, 4, 5, 5, 4, 2, 5, 4, 1, 5, 2, 4, 4, 0, 3, 2, 4, 3, 3, 1, 5, 0, 5, 4, 3, 0, 3, 0, 1, 2, 4, 1, 3, 0, 0, 0, 3, 5, 2, 0, 1, 5, 4, 2, 0, 1, 0, 5, 1, 4, 5, 2, 1, 4, 5, 3, 1, 4, 4, 1, 1, 2, 1, 2, 3, 2, 0, 0, 0, 2, 4, 3, 2, 4, 1, 3, 1, 0, 2, 1, 2, 5, 3, 1, 0, 3, 4, 5, 4, 3, 0, 5, 0, 0, 1, 1, 1, 0, 4, 2, 3, 5, 5, 5, 5, 4, 2, 4, 2, 4, 0, 4, 2, 0, 2, 2, 3, 1, 1, 2, 5, 5, 0, 5, 4, 1, 5, 5, 0, 3, 3, 4, 0, 5, 0, 5, 0, 3, 4, 1, 0, 2, 2, 4, 2, 3, 3, 0, 4, 0, 4, 2, 5, 0, 0, 5, 1, 1, 1, 1, 4, 4, 4, 2, 2, 4, 0, 1, 0, 0, 2, 3, 3, 0, 0, 3, 1, 0, 0, 3, 5, 4, 0, 5, 3, 3, 5, 5, 5, 3, 4, 4, 3, 1, 1, 0, 1, 1, 3, 2, 3, 1, 3, 5, 3, 0, 1, 3, 4, 0, 0, 5, 1, 5, 3, 1, 1, 3, 5, 5, 1, 5, 0, 4, 4, 5, 3, 5, 1, 1, 5, 0, 1, 1, 4, 0, 5, 2, 5, 4, 3, 2, 3, 1, 1, 5, 3, 0, 3, 0, 3, 5, 1, 1, 0, 5, 3, 2, 0, 0, 3, 1, 0, 1, 4, 0, 4, 4, 5, 5, 5, 0, 3, 5, 3, 3, 5, 1, 3, 5, 1, 3, 5, 2, 5, 1, 2, 5, 2, 2, 2, 1, 3, 3, 2, 0, 0, 1, 1, 2, 2, 2, 0, 5, 1, 4, 5, 4, 2, 4, 2, 5, 5, 5, 0, 0, 4, 1, 1, 0, 4, 5, 5, 5, 0, 0, 5, 5, 5, 4, 1, 2, 4, 4, 4, 0, 2, 5, 0, 0, 1, 1, 2, 4, 4, 2, 0, 3, 1, 4, 0, 1, 0, 2, 5, 0, 1, 2, 1, 3, 0, 4, 4, 2, 1, 5, 0, 0, 1, 5, 0, 4, 4, 3, 0, 1, 5, 0, 2, 2, 5, 1, 5, 2, 0, 0, 4, 2, 3, 4, 1, 1, 3, 0, 0, 5, 1, 1, 3, 2, 2, 5, 1, 4, 4, 5, 5, 1, 3, 3, 0, 0, 5, 3, 0, 1, 3, 3, 1, 3, 0, 4, 2, 3, 4, 2, 1, 4, 3, 3, 5, 3, 4, 4, 3, 0, 2, 0, 1, 2, 4, 5, 4, 4, 0, 0, 3, 4, 4, 2, 0, 4, 4, 4, 4, 1, 3, 5, 3, 1, 5, 5, 4, 3, 3, 5, 3, 5, 2, 2, 2, 4, 4, 0, 0, 1, 3, 3, 3, 3, 3, 2, 0, 3, 5, 3, 1, 5, 1, 0, 4, 0, 2, 3, 2, 3, 0, 2, 1, 2, 4, 4, 4, 0, 3, 2, 2, 2, 1, 0, 3, 3, 4, 4, 3, 1, 5, 3, 3, 2, 0, 0, 0, 0, 4, 5, 0, 1, 5, 5, 0, 0, 4, 3, 1, 4, 4, 0, 3, 3, 4, 5, 3, 5, 1, 1, 2, 5, 4, 0, 5, 1, 1, 0, 3, 4, 0, 0, 5, 1, 3, 5, 4, 2, 2, 1, 1, 5, 5, 3, 4, 3, 0, 3, 5, 5, 5, 1, 4, 5, 5, 0, 0, 4, 1, 1, 0, 5, 4, 0, 5, 0, 4, 3, 0, 1, 4, 0, 0, 4, 3, 4, 2, 3, 1, 3, 5, 5, 0, 0, 5, 2, 4, 1, 0, 3, 4, 1, 2, 4, 1, 3, 1, 1, 0, 0, 2, 3, 5, 3, 2, 3, 3, 3, 1, 4, 4, 1, 1, 2, 4, 5, 5, 1, 0, 2, 2, 0, 0, 3, 1, 3, 4, 2, 2, 0, 4, 4, 1, 0, 0, 0, 3, 5, 5, 5, 2, 4, 4, 5, 2, 0, 1, 3, 3, 3, 5, 0, 1, 0, 2, 2, 2, 2, 2, 2, 3, 4, 3, 3, 3, 1, 0, 3, 2, 1, 3, 1, 4, 5, 3, 3, 1, 2, 2, 0, 4, 0, 3, 5, 1, 0, 4, 2, 4, 1, 4, 2, 3, 1, 1, 3, 5, 2, 5, 3, 3, 5, 4, 5, 1, 0, 0, 2, 4, 0, 5, 4, 5, 4, 2, 3, 1, 5, 5, 0, 5, 3, 3, 1, 5, 2, 2, 5, 3, 4, 0, 1, 3, 1, 0, 5, 0, 5, 0, 4, 4, 3, 3, 3, 4, 0, 2, 3, 2, 4, 3, 3, 2, 4, 2, 2, 1, 3, 1, 3, 3, 4, 3, 5, 4, 1, 0, 1, 3, 4, 2, 3, 4, 4, 3, 4, 1, 0, 3, 2, 1, 2, 4, 5, 3, 3, 5, 5, 5, 2, 5, 1, 2, 2, 1, 1, 2, 1, 0, 5, 3, 0, 4, 4, 3, 0, 2, 0, 2, 4, 2, 2, 4, 4, 2, 3, 3, 0, 0, 1, 1, 0, 4, 4, 0, 5, 5, 3, 3, 5, 1, 1, 3, 0, 0, 3, 0, 5, 5, 4, 0, 4, 5, 5, 0, 5, 3, 4, 2, 3, 1, 3, 3, 5, 5, 2, 3, 5, 5, 0, 0, 5, 3, 5, 4, 3, 1, 1, 0, 1, 5, 4, 1, 3, 5, 5, 2, 2, 3, 2, 5, 5, 0, 4, 1, 3, 3, 3, 5, 4, 2, 2, 1, 2, 0, 2, 3, 0, 1, 4, 2, 1, 4, 0, 0, 1, 2, 3, 0, 0, 1, 3, 4, 3, 5, 2, 1, 1, 1, 2, 2, 2, 0, 2, 5, 5, 4, 3, 3, 3, 5, 4, 2, 1, 1, 1, 1, 4, 2, 2, 2, 2, 4, 5, 4, 0, 1, 4, 0, 3, 0, 0, 5, 0, 2, 4, 3, 3, 5, 1, 5, 4, 0, 4, 4, 5, 3, 0, 0, 1, 4, 3, 2, 1, 1, 5, 5, 0, 0, 0, 3, 4, 2, 2, 1, 5, 2, 2, 3, 2, 2, 5, 5, 4, 2, 1, 0, 5, 3, 3, 0, 2, 5, 4, 4, 2, 2, 4, 0, 0, 2, 0, 4, 0, 2, 0, 0, 5, 3, 2, 1, 2, 5, 3, 1, 0, 2, 0, 0, 5, 0, 0, 5, 1, 1, 3, 5, 2, 5, 2, 3, 3, 1, 0, 2, 2, 1, 1, 3, 2, 2, 0, 1, 4, 2, 4, 2, 4, 1, 3, 2, 5, 4, 4, 4, 5, 2, 5, 5, 0, 5, 4, 5, 4, 5, 1, 5, 4, 2, 2, 3, 1, 1, 2, 0, 4, 3, 0, 5, 1, 1, 4, 2, 3, 5, 2, 4, 5, 5, 2, 3, 1, 0, 0, 4, 5, 3, 2, 1, 2, 4, 5, 4, 4, 1, 1, 1, 4, 5, 4, 3, 1, 2, 2, 0, 4, 4, 4, 0, 3, 3, 3, 5, 2, 3, 0, 4, 3, 1, 2, 1, 0, 0, 5, 5, 0, 2, 1, 3, 1, 3, 0, 5, 4, 4, 3, 1, 3, 2, 1, 0, 5, 0, 4, 4, 1, 4, 0, 2, 3, 5, 0, 5, 4, 4, 0, 1, 1, 1, 2, 3, 5, 1, 0, 0, 1, 1, 5, 1, 1, 0, 2, 1, 0, 1, 4, 2, 1, 3, 0, 3, 0, 1, 3, 2, 4, 0, 3, 0, 1, 1, 0, 1, 2, 4, 1, 2, 3, 3, 5, 3, 4, 3, 2, 2, 1, 1, 0, 2, 2, 5, 3, 3, 0, 3, 2, 5, 3, 3, 3, 2, 3, 1, 5, 3, 2, 2, 1, 1, 5, 5, 2, 0, 3, 2, 0, 4, 4, 2, 4, 5, 5, 3, 1, 1, 0, 2, 1, 2, 1, 2, 5, 3, 3, 1, 3, 2, 1, 3, 3, 0, 3, 4, 1, 4, 2, 3, 3, 2, 3, 5, 2, 5, 3, 5, 2, 4, 2, 1, 2, 2, 0, 1, 2, 3, 3, 4, 0, 3, 5, 0, 2, 5, 0, 3, 3, 4, 2, 3, 5, 4, 3, 1, 3, 4, 3, 4, 1, 2, 5, 2, 2, 0, 0, 4, 0, 1, 4, 2, 0, 1, 1, 0, 5, 0, 4, 4, 4, 4, 5, 2, 4, 1, 4, 3, 2, 2, 1, 2, 5, 3, 1, 5, 5, 4, 5, 4, 0, 4, 3, 3, 1, 4, 3, 5, 3, 5, 3, 0, 0, 3, 4, 1, 4, 4, 3, 5, 2, 3, 4, 4, 1, 4, 5, 3, 0, 2, 5, 0, 0, 1, 4, 1, 5, 3, 1, 5, 1, 5, 5, 0, 3, 3, 3, 4, 0, 1, 5, 2, 5, 2, 0, 5, 1, 2, 4, 3, 1, 0, 0, 5, 2, 0, 5, 5, 1, 5, 1, 2, 4, 4, 4, 3, 5, 1, 4, 4, 0, 4, 4, 4, 2, 5, 5, 5, 2, 4, 3, 0, 2, 2, 0, 2, 3, 4, 3, 1, 1, 5, 2, 2, 4, 0, 1, 3, 3, 4, 0, 5, 3, 2, 0, 0, 1, 4, 3, 1, 1, 5, 2, 2, 2, 3, 0, 4, 0, 2, 4, 0, 3, 5, 5, 0, 3, 3, 1, 5, 1, 0, 4, 5, 4, 5, 3, 1, 2, 0, 5, 0, 4, 3, 1, 4, 2, 4, 5, 0, 0, 2, 1, 4, 2, 4, 3, 1, 0, 4, 1, 0, 1, 3, 2, 1, 0, 4, 1, 1, 3, 2, 2, 2, 2, 2, 0, 2, 4, 5, 0, 5, 3, 4, 4, 1, 2, 0, 0, 0, 4, 5, 4, 3, 1, 0, 2, 3, 5, 1, 5, 0, 3, 0, 4, 2, 5, 5, 0, 2, 5, 0, 4, 2, 5, 2, 4, 0, 2, 1, 1, 0, 1, 3, 5, 1, 2, 0, 1, 1, 2, 0, 1, 3, 2, 2, 2, 2, 2, 3, 1, 4, 0, 3, 3, 3, 3, 1, 0, 5, 4, 1, 3, 0, 2, 0, 0, 4, 2, 4, 0, 4, 2, 5, 4, 3, 1, 2, 2, 1, 1, 5, 1, 4, 0, 3, 4, 5, 4, 5, 5, 1, 0, 3, 1, 4, 2, 3, 4, 0, 4, 1, 0, 2, 1, 4, 4, 5, 3, 4, 5, 0, 4, 2, 2, 5, 4, 1, 2, 5, 4, 2, 5, 1, 3, 0, 1, 5, 1, 3, 4, 1, 0, 4, 4, 5, 1, 4, 4, 4, 1, 3, 2, 2, 2, 0, 3, 4, 3, 2, 3, 5, 1, 1, 5, 3, 4, 1, 3, 4, 0, 2, 5, 1, 2, 4, 5, 5, 5, 5, 5, 2, 5, 1, 4, 4, 3, 5, 2, 0, 3, 4, 1, 1, 1, 4, 4, 0, 2, 5, 2, 4, 0, 3, 0, 4, 5, 2, 3, 5, 3, 0, 0, 0, 5, 4, 2, 5, 1, 4, 4, 4, 5, 1, 2, 1, 0, 4, 5, 3, 1, 1, 1, 4, 5, 4, 3, 2, 3, 0, 3, 3, 2, 1, 3, 3, 0, 4, 4, 0, 4, 3, 0, 1, 2, 4, 4, 2, 0, 5, 5, 2, 1, 2, 5, 5, 1, 5, 2, 1, 1, 2, 2, 5, 3, 1, 1, 5, 0, 3, 4, 1, 2, 4, 0, 1, 2, 1, 1, 2, 2, 5, 4, 2, 4, 5, 2, 5, 2, 1, 1, 4, 0, 3, 0, 5, 3, 5, 2, 3, 2, 4, 3, 5, 0, 3, 2, 2, 1, 2, 5, 5, 4, 5, 1, 0, 4, 5, 1, 1, 5, 5, 1, 4, 2, 2, 1, 3, 2, 5, 2, 1, 0, 2, 2, 0, 3, 2, 3, 3, 4, 5, 0, 1, 2, 4, 4, 1, 0, 1, 2, 5, 3, 1, 5, 2, 2, 3, 0, 2, 3, 4, 5, 5, 4, 0, 1, 2, 5, 0, 3, 1, 4, 2, 2, 4, 4, 5, 3, 5, 3, 4, 4, 2, 5, 0, 2, 1, 1, 2, 1, 3, 2, 4, 1, 1, 3, 1, 2, 5, 2, 2, 0, 1, 0, 3, 0, 5, 4, 5, 3, 0, 4, 2, 5, 2, 2, 0, 1, 4, 2, 3, 5, 2, 0, 5, 1, 3, 1, 1, 1, 1, 0, 5, 4, 5, 1, 4, 5, 3, 4, 3, 0, 5, 4, 1, 0, 2, 0, 1, 1, 0, 2, 0, 4, 1, 5, 0, 3, 0, 1, 0, 0, 0, 4, 1, 2, 5, 2, 3, 5, 1, 1, 0, 0, 3, 4, 3, 3, 4, 3, 5, 5, 1, 5, 4, 4, 4, 5, 5, 3, 0, 4, 5, 1, 2, 0, 1, 2, 5, 1, 4, 4, 3, 3, 5, 2, 3, 3, 0, 3, 1, 4, 4, 4, 5, 0, 3, 3, 1, 5, 1, 5, 0, 0, 5, 2, 3, 4, 1, 0, 3, 2, 4, 2, 5, 2, 1, 1, 4, 2, 5, 1, 2, 5, 0, 5, 1, 3, 5, 0, 3, 0, 2, 4, 0, 1, 5, 4, 1, 1, 2, 3, 3, 1, 5, 2, 4, 5, 2, 0, 2, 2, 0, 4, 4, 0, 3, 1, 4, 5, 4, 5, 4, 5, 4, 4, 0, 1, 0, 1, 4, 1, 0, 0, 4, 2, 1, 0, 2, 4, 3, 2, 5, 2, 4, 5, 1, 5, 3, 0, 0, 1, 0, 3, 5, 1, 3, 4, 3, 0, 3, 3, 4, 0, 5, 3, 2, 2, 1, 5, 4, 0, 1, 4, 2, 3, 0, 3, 5, 2, 3, 0, 2, 5, 3, 1, 5, 1, 5, 3, 2, 5, 0, 2, 1, 5, 2, 1, 0, 4, 0, 0, 4, 5, 0, 5, 0, 4, 1, 2, 3, 0, 3, 3, 1, 5, 4, 3, 3, 1, 5, 4, 3, 4, 5, 0, 2, 4, 4, 2, 2, 1, 0, 2, 5, 5, 3, 2, 4, 1, 3, 3, 1, 2, 3, 2, 4, 0, 3, 1, 1, 1, 4, 1, 0, 2, 2, 4, 4, 5, 5, 4, 3, 5, 5, 4, 1, 5, 2, 4, 2, 3, 2, 0, 4, 4, 4, 2, 2, 3, 3, 1, 2, 1, 2, 3, 3, 3, 3, 0, 4, 1, 1, 3, 4, 1, 0, 1, 0, 4, 4, 4, 4, 4, 5, 5, 0, 2, 3, 3, 4, 0, 5, 4, 5, 5, 5, 1, 5, 4, 4, 2, 2, 5, 5, 5, 0, 3, 0, 3, 5, 3, 3, 3, 1, 4, 1, 2, 2, 1, 5, 1, 0, 4, 1, 3, 0, 0, 5, 5, 2, 5, 3, 3, 1, 5, 5, 0, 0, 3, 1, 1, 1, 1, 4, 0, 1, 0, 5, 4, 2, 2, 4, 0, 2, 2, 5, 1, 2, 1, 3, 5, 3, 2, 5, 0, 2, 0, 0, 1, 2, 3, 3, 0, 5, 5, 4, 0, 0, 4, 1, 5, 2, 1, 2, 4, 4, 0, 0, 0, 3, 0, 3, 4, 5, 0, 2, 1, 5, 5, 3, 1, 3, 2, 0, 1, 0, 3, 4, 0, 5, 4, 4, 1, 2, 2, 3, 0, 5, 4, 3, 2, 0, 3, 4, 2, 5, 2, 0, 2, 1, 3, 4, 0, 4, 3, 4, 3, 0, 2, 3, 4, 3, 3, 1, 2, 5, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:amwnexc5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017c15b7e84047b180ce49b33131f8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▅▂▁▃▄▇▇▆▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>eval/loss</td><td>▇▆▇▆▅▁▁▁▂▂▂▂▅▄▅▆▇██</td></tr><tr><td>eval/runtime</td><td>█▆▆▅▅▃▃▅█▄▆▆▆▄▁▂█▃▇</td></tr><tr><td>eval/samples_per_second</td><td>▁▃▃▃▄▆▆▄▁▄▃▃▃▅█▆▁▆▂</td></tr><tr><td>eval/steps_per_second</td><td>▁▃▃▃▄▆▆▄▁▄▃▃▃▅█▆▁▆▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▁▁▁▁▁▁▁▂▁▁▁▂▁▂▁▁█▁▂▂▁▁▃▁▂▃▃▁▁▁▁▂▁▁▃▁▂▂▂▁</td></tr><tr><td>train/learning_rate</td><td>▂▅███▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▆▇▆▆▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.43542</td></tr><tr><td>eval/loss</td><td>1.56644</td></tr><tr><td>eval/runtime</td><td>3.1392</td></tr><tr><td>eval/samples_per_second</td><td>152.906</td></tr><tr><td>eval/steps_per_second</td><td>19.113</td></tr><tr><td>train/epoch</td><td>19.07407</td></tr><tr><td>train/global_step</td><td>10300</td></tr><tr><td>train/grad_norm</td><td>13.51963</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7663</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">030</strong> at: <a href='https://wandb.ai/m-kai-d/Cam01/runs/amwnexc5' target=\"_blank\">https://wandb.ai/m-kai-d/Cam01/runs/amwnexc5</a><br/> View project at: <a href='https://wandb.ai/m-kai-d/Cam01' target=\"_blank\">https://wandb.ai/m-kai-d/Cam01</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240521_223345-amwnexc5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:amwnexc5). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4ba354f4014d6a83f43c9ce46a0901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01127777777777131, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\projects\\Matthias\\proj_01\\wandb\\run-20240521_230412-7j5q02zj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/m-kai-d/Cam01/runs/7j5q02zj' target=\"_blank\">031</a></strong> to <a href='https://wandb.ai/m-kai-d/Cam01' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/m-kai-d/Cam01' target=\"_blank\">https://wandb.ai/m-kai-d/Cam01</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/m-kai-d/Cam01/runs/7j5q02zj' target=\"_blank\">https://wandb.ai/m-kai-d/Cam01/runs/7j5q02zj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e84be7091c4a4a916e1acda816ec59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7312, 'grad_norm': 30.35347557067871, 'learning_rate': 4.7000000000000005e-07, 'epoch': 0.09}\n",
      "{'loss': 0.7772, 'grad_norm': 65.6285400390625, 'learning_rate': 9.7e-07, 'epoch': 0.19}\n",
      "{'loss': 0.8193, 'grad_norm': 72.19319915771484, 'learning_rate': 1.4700000000000001e-06, 'epoch': 0.28}\n",
      "{'loss': 0.7669, 'grad_norm': 315.2063293457031, 'learning_rate': 1.97e-06, 'epoch': 0.37}\n",
      "{'loss': 0.8404, 'grad_norm': 41.567604064941406, 'learning_rate': 2.46e-06, 'epoch': 0.46}\n",
      "{'loss': 0.7997, 'grad_norm': 113.6792221069336, 'learning_rate': 2.96e-06, 'epoch': 0.56}\n",
      "{'loss': 0.8499, 'grad_norm': 97.47808074951172, 'learning_rate': 3.46e-06, 'epoch': 0.65}\n",
      "{'loss': 0.8188, 'grad_norm': 65.74834442138672, 'learning_rate': 3.96e-06, 'epoch': 0.74}\n",
      "{'loss': 0.8508, 'grad_norm': 17.316129684448242, 'learning_rate': 4.4600000000000005e-06, 'epoch': 0.83}\n",
      "{'loss': 0.8758, 'grad_norm': 44.10124588012695, 'learning_rate': 4.960000000000001e-06, 'epoch': 0.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78dd5276dacc473e91f09c194deca947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5323176383972168, 'eval_accuracy': 0.4375, 'eval_runtime': 3.5239, 'eval_samples_per_second': 136.213, 'eval_steps_per_second': 17.027, 'epoch': 1.0}\n",
      "{'loss': 0.8848, 'grad_norm': 268.7453918457031, 'learning_rate': 4.977669902912622e-06, 'epoch': 1.02}\n",
      "{'loss': 0.8367, 'grad_norm': 155.93505859375, 'learning_rate': 4.953398058252428e-06, 'epoch': 1.11}\n",
      "{'loss': 0.7899, 'grad_norm': 17.261123657226562, 'learning_rate': 4.929126213592234e-06, 'epoch': 1.2}\n",
      "{'loss': 0.8142, 'grad_norm': 108.66139221191406, 'learning_rate': 4.904854368932039e-06, 'epoch': 1.3}\n",
      "{'loss': 0.8297, 'grad_norm': 74.90510559082031, 'learning_rate': 4.880582524271845e-06, 'epoch': 1.39}\n",
      "{'loss': 0.8932, 'grad_norm': 104.79979705810547, 'learning_rate': 4.856310679611651e-06, 'epoch': 1.48}\n",
      "{'loss': 0.7787, 'grad_norm': 162.87759399414062, 'learning_rate': 4.8320388349514566e-06, 'epoch': 1.57}\n",
      "{'loss': 0.8837, 'grad_norm': 24.408370971679688, 'learning_rate': 4.807766990291262e-06, 'epoch': 1.67}\n",
      "{'loss': 0.8969, 'grad_norm': 93.17027282714844, 'learning_rate': 4.783495145631069e-06, 'epoch': 1.76}\n",
      "{'loss': 0.8571, 'grad_norm': 71.1850814819336, 'learning_rate': 4.759223300970875e-06, 'epoch': 1.85}\n",
      "{'loss': 0.776, 'grad_norm': 28.55072593688965, 'learning_rate': 4.73495145631068e-06, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2a46c433ac4236a4366b961a951fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5600697994232178, 'eval_accuracy': 0.44166666666666665, 'eval_runtime': 2.7299, 'eval_samples_per_second': 175.829, 'eval_steps_per_second': 21.979, 'epoch': 2.0}\n",
      "{'loss': 0.8406, 'grad_norm': 51.37070083618164, 'learning_rate': 4.710679611650486e-06, 'epoch': 2.04}\n",
      "{'loss': 0.84, 'grad_norm': 145.562255859375, 'learning_rate': 4.686407766990292e-06, 'epoch': 2.13}\n",
      "{'loss': 0.7875, 'grad_norm': 45.944847106933594, 'learning_rate': 4.6621359223300975e-06, 'epoch': 2.22}\n",
      "{'loss': 0.8221, 'grad_norm': 55.789459228515625, 'learning_rate': 4.637864077669903e-06, 'epoch': 2.31}\n",
      "{'loss': 0.766, 'grad_norm': 155.41590881347656, 'learning_rate': 4.614077669902912e-06, 'epoch': 2.41}\n",
      "{'loss': 0.776, 'grad_norm': 94.18099212646484, 'learning_rate': 4.589805825242719e-06, 'epoch': 2.5}\n",
      "{'loss': 0.7659, 'grad_norm': 30.053733825683594, 'learning_rate': 4.565533980582525e-06, 'epoch': 2.59}\n",
      "{'loss': 0.7957, 'grad_norm': 19.016712188720703, 'learning_rate': 4.54126213592233e-06, 'epoch': 2.69}\n",
      "{'loss': 0.7278, 'grad_norm': 24.680810928344727, 'learning_rate': 4.516990291262136e-06, 'epoch': 2.78}\n",
      "{'loss': 0.8218, 'grad_norm': 44.069114685058594, 'learning_rate': 4.492718446601942e-06, 'epoch': 2.87}\n",
      "{'loss': 0.7845, 'grad_norm': 112.55115509033203, 'learning_rate': 4.4684466019417476e-06, 'epoch': 2.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfd9af7413b451e833615c5645d91fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6081445217132568, 'eval_accuracy': 0.45625, 'eval_runtime': 3.0815, 'eval_samples_per_second': 155.767, 'eval_steps_per_second': 19.471, 'epoch': 3.0}\n",
      "{'loss': 0.8714, 'grad_norm': 60.209476470947266, 'learning_rate': 4.444174757281553e-06, 'epoch': 3.06}\n",
      "{'loss': 0.8869, 'grad_norm': 38.636470794677734, 'learning_rate': 4.419902912621359e-06, 'epoch': 3.15}\n",
      "{'loss': 0.7051, 'grad_norm': 132.5801544189453, 'learning_rate': 4.395631067961166e-06, 'epoch': 3.24}\n",
      "{'loss': 0.784, 'grad_norm': 32.69548797607422, 'learning_rate': 4.371359223300971e-06, 'epoch': 3.33}\n",
      "{'loss': 0.7707, 'grad_norm': 77.05297088623047, 'learning_rate': 4.347087378640777e-06, 'epoch': 3.43}\n",
      "{'loss': 0.7031, 'grad_norm': 21.45731544494629, 'learning_rate': 4.322815533980583e-06, 'epoch': 3.52}\n",
      "{'loss': 0.7634, 'grad_norm': 23.770307540893555, 'learning_rate': 4.2985436893203885e-06, 'epoch': 3.61}\n",
      "{'loss': 0.7321, 'grad_norm': 73.38613891601562, 'learning_rate': 4.274271844660194e-06, 'epoch': 3.7}\n",
      "{'loss': 0.6991, 'grad_norm': 154.90782165527344, 'learning_rate': 4.25e-06, 'epoch': 3.8}\n",
      "{'loss': 0.7688, 'grad_norm': 81.43114471435547, 'learning_rate': 4.225728155339806e-06, 'epoch': 3.89}\n",
      "{'loss': 0.8087, 'grad_norm': 143.62025451660156, 'learning_rate': 4.201456310679612e-06, 'epoch': 3.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8697cd7ecb114c808d2eef0ec44a2484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6352604627609253, 'eval_accuracy': 0.44583333333333336, 'eval_runtime': 3.0995, 'eval_samples_per_second': 154.864, 'eval_steps_per_second': 19.358, 'epoch': 4.0}\n",
      "{'loss': 0.751, 'grad_norm': 25.362733840942383, 'learning_rate': 4.177184466019418e-06, 'epoch': 4.07}\n",
      "{'loss': 0.7414, 'grad_norm': 10.609882354736328, 'learning_rate': 4.152912621359224e-06, 'epoch': 4.17}\n",
      "{'loss': 0.6781, 'grad_norm': 106.3929672241211, 'learning_rate': 4.1286407766990295e-06, 'epoch': 4.26}\n",
      "{'loss': 0.7133, 'grad_norm': 166.91519165039062, 'learning_rate': 4.104368932038835e-06, 'epoch': 4.35}\n",
      "{'loss': 0.7811, 'grad_norm': 17.731630325317383, 'learning_rate': 4.080097087378641e-06, 'epoch': 4.44}\n",
      "{'loss': 0.7757, 'grad_norm': 14.391282081604004, 'learning_rate': 4.055825242718447e-06, 'epoch': 4.54}\n",
      "{'loss': 0.7071, 'grad_norm': 40.011634826660156, 'learning_rate': 4.031553398058252e-06, 'epoch': 4.63}\n",
      "{'loss': 0.7495, 'grad_norm': 56.87904739379883, 'learning_rate': 4.007281553398059e-06, 'epoch': 4.72}\n",
      "{'loss': 0.7236, 'grad_norm': 48.906742095947266, 'learning_rate': 3.983009708737865e-06, 'epoch': 4.81}\n",
      "{'loss': 0.7137, 'grad_norm': 147.85842895507812, 'learning_rate': 3.95873786407767e-06, 'epoch': 4.91}\n",
      "{'loss': 0.7423, 'grad_norm': 63.50514221191406, 'learning_rate': 3.934466019417476e-06, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5295e14858e642b9afd1c9d6d12a477d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7447766065597534, 'eval_accuracy': 0.45, 'eval_runtime': 3.2907, 'eval_samples_per_second': 145.865, 'eval_steps_per_second': 18.233, 'epoch': 5.0}\n",
      "{'loss': 0.6625, 'grad_norm': 82.86161041259766, 'learning_rate': 3.910194174757282e-06, 'epoch': 5.09}\n",
      "{'loss': 0.6709, 'grad_norm': 26.271238327026367, 'learning_rate': 3.885922330097088e-06, 'epoch': 5.19}\n",
      "{'loss': 0.6523, 'grad_norm': 78.52384185791016, 'learning_rate': 3.861650485436893e-06, 'epoch': 5.28}\n",
      "{'loss': 0.7069, 'grad_norm': 48.74520492553711, 'learning_rate': 3.837378640776699e-06, 'epoch': 5.37}\n",
      "{'loss': 0.7647, 'grad_norm': 30.797245025634766, 'learning_rate': 3.813106796116505e-06, 'epoch': 5.46}\n",
      "{'loss': 0.7691, 'grad_norm': 53.92286682128906, 'learning_rate': 3.788834951456311e-06, 'epoch': 5.56}\n",
      "{'loss': 0.7075, 'grad_norm': 145.8514404296875, 'learning_rate': 3.764563106796117e-06, 'epoch': 5.65}\n",
      "{'loss': 0.6471, 'grad_norm': 27.172225952148438, 'learning_rate': 3.740291262135923e-06, 'epoch': 5.74}\n",
      "{'loss': 0.8063, 'grad_norm': 36.27922439575195, 'learning_rate': 3.7160194174757285e-06, 'epoch': 5.83}\n",
      "{'loss': 0.6296, 'grad_norm': 216.96543884277344, 'learning_rate': 3.6917475728155343e-06, 'epoch': 5.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8573d87c081e4670b83324b61e9f8829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7780641317367554, 'eval_accuracy': 0.4354166666666667, 'eval_runtime': 3.1565, 'eval_samples_per_second': 152.065, 'eval_steps_per_second': 19.008, 'epoch': 6.0}\n",
      "{'loss': 0.6412, 'grad_norm': 33.31379699707031, 'learning_rate': 3.6674757281553404e-06, 'epoch': 6.02}\n",
      "{'loss': 0.6525, 'grad_norm': 88.24898529052734, 'learning_rate': 3.643203883495146e-06, 'epoch': 6.11}\n",
      "{'loss': 0.831, 'grad_norm': 102.02548217773438, 'learning_rate': 3.618932038834952e-06, 'epoch': 6.2}\n",
      "{'loss': 0.6378, 'grad_norm': 149.39561462402344, 'learning_rate': 3.5946601941747576e-06, 'epoch': 6.3}\n",
      "{'loss': 0.585, 'grad_norm': 44.55949401855469, 'learning_rate': 3.5708737864077676e-06, 'epoch': 6.39}\n",
      "{'loss': 0.6521, 'grad_norm': 31.541414260864258, 'learning_rate': 3.5466019417475733e-06, 'epoch': 6.48}\n",
      "{'loss': 0.6803, 'grad_norm': 113.04843139648438, 'learning_rate': 3.522330097087379e-06, 'epoch': 6.57}\n",
      "{'loss': 0.7048, 'grad_norm': 126.50230407714844, 'learning_rate': 3.498058252427185e-06, 'epoch': 6.67}\n",
      "{'loss': 0.6508, 'grad_norm': 80.10124206542969, 'learning_rate': 3.473786407766991e-06, 'epoch': 6.76}\n",
      "{'loss': 0.7857, 'grad_norm': 206.3302001953125, 'learning_rate': 3.4495145631067966e-06, 'epoch': 6.85}\n",
      "{'loss': 0.6098, 'grad_norm': 23.413026809692383, 'learning_rate': 3.4252427184466024e-06, 'epoch': 6.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de856824eeb4236a1e559dc1edd9ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.78048574924469, 'eval_accuracy': 0.45625, 'eval_runtime': 3.0491, 'eval_samples_per_second': 157.425, 'eval_steps_per_second': 19.678, 'epoch': 7.0}\n",
      "{'loss': 0.7145, 'grad_norm': 112.61077880859375, 'learning_rate': 3.4009708737864077e-06, 'epoch': 7.04}\n",
      "{'loss': 0.6546, 'grad_norm': 14.78670597076416, 'learning_rate': 3.376699029126214e-06, 'epoch': 7.13}\n",
      "{'loss': 0.6455, 'grad_norm': 191.2918701171875, 'learning_rate': 3.3524271844660195e-06, 'epoch': 7.22}\n",
      "{'loss': 0.7055, 'grad_norm': 57.47028732299805, 'learning_rate': 3.3281553398058253e-06, 'epoch': 7.31}\n",
      "{'loss': 0.6702, 'grad_norm': 320.6011962890625, 'learning_rate': 3.303883495145631e-06, 'epoch': 7.41}\n",
      "{'loss': 0.6402, 'grad_norm': 57.43450164794922, 'learning_rate': 3.279611650485437e-06, 'epoch': 7.5}\n",
      "{'loss': 0.6507, 'grad_norm': 33.11213302612305, 'learning_rate': 3.255339805825243e-06, 'epoch': 7.59}\n",
      "{'loss': 0.6723, 'grad_norm': 37.9508171081543, 'learning_rate': 3.2310679611650486e-06, 'epoch': 7.69}\n",
      "{'loss': 0.6375, 'grad_norm': 277.6802673339844, 'learning_rate': 3.2067961165048543e-06, 'epoch': 7.78}\n",
      "{'loss': 0.6334, 'grad_norm': 53.536380767822266, 'learning_rate': 3.1825242718446605e-06, 'epoch': 7.87}\n",
      "{'loss': 0.6353, 'grad_norm': 35.4046745300293, 'learning_rate': 3.1582524271844662e-06, 'epoch': 7.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa83184ab964ad5b0637c34d5f61757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8110547065734863, 'eval_accuracy': 0.4354166666666667, 'eval_runtime': 2.9156, 'eval_samples_per_second': 164.631, 'eval_steps_per_second': 20.579, 'epoch': 8.0}\n",
      "{'loss': 0.6198, 'grad_norm': 56.304256439208984, 'learning_rate': 3.133980582524272e-06, 'epoch': 8.06}\n",
      "{'loss': 0.6442, 'grad_norm': 160.39544677734375, 'learning_rate': 3.1097087378640777e-06, 'epoch': 8.15}\n",
      "{'loss': 0.6972, 'grad_norm': 44.615787506103516, 'learning_rate': 3.085436893203884e-06, 'epoch': 8.24}\n",
      "{'loss': 0.6028, 'grad_norm': 28.834489822387695, 'learning_rate': 3.0611650485436896e-06, 'epoch': 8.33}\n",
      "{'loss': 0.6033, 'grad_norm': 125.77525329589844, 'learning_rate': 3.0368932038834953e-06, 'epoch': 8.43}\n",
      "{'loss': 0.6645, 'grad_norm': 46.047218322753906, 'learning_rate': 3.012621359223301e-06, 'epoch': 8.52}\n",
      "{'loss': 0.6286, 'grad_norm': 53.27299499511719, 'learning_rate': 2.988349514563107e-06, 'epoch': 8.61}\n",
      "{'loss': 0.6545, 'grad_norm': 58.40275955200195, 'learning_rate': 2.964077669902913e-06, 'epoch': 8.7}\n",
      "{'loss': 0.6003, 'grad_norm': 41.68008041381836, 'learning_rate': 2.9398058252427186e-06, 'epoch': 8.8}\n",
      "{'loss': 0.5439, 'grad_norm': 19.46708106994629, 'learning_rate': 2.9155339805825244e-06, 'epoch': 8.89}\n",
      "{'loss': 0.5669, 'grad_norm': 14.692941665649414, 'learning_rate': 2.8912621359223305e-06, 'epoch': 8.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335e3694ac7a4fb2a30b1aae824a3278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8566627502441406, 'eval_accuracy': 0.45416666666666666, 'eval_runtime': 3.3669, 'eval_samples_per_second': 142.563, 'eval_steps_per_second': 17.82, 'epoch': 9.0}\n",
      "{'loss': 0.626, 'grad_norm': 172.56405639648438, 'learning_rate': 2.8669902912621362e-06, 'epoch': 9.07}\n",
      "{'loss': 0.5122, 'grad_norm': 40.59516906738281, 'learning_rate': 2.842718446601942e-06, 'epoch': 9.17}\n",
      "{'loss': 0.6109, 'grad_norm': 30.68539810180664, 'learning_rate': 2.8184466019417477e-06, 'epoch': 9.26}\n",
      "{'loss': 0.6196, 'grad_norm': 359.0010986328125, 'learning_rate': 2.7941747572815534e-06, 'epoch': 9.35}\n",
      "{'loss': 0.5363, 'grad_norm': 186.63514709472656, 'learning_rate': 2.7699029126213596e-06, 'epoch': 9.44}\n",
      "{'loss': 0.5696, 'grad_norm': 65.92540740966797, 'learning_rate': 2.7456310679611653e-06, 'epoch': 9.54}\n",
      "{'loss': 0.6669, 'grad_norm': 317.18157958984375, 'learning_rate': 2.721359223300971e-06, 'epoch': 9.63}\n",
      "{'loss': 0.6161, 'grad_norm': 64.0517349243164, 'learning_rate': 2.6970873786407768e-06, 'epoch': 9.72}\n",
      "{'loss': 0.6599, 'grad_norm': 67.79966735839844, 'learning_rate': 2.672815533980583e-06, 'epoch': 9.81}\n",
      "{'loss': 0.636, 'grad_norm': 18.97593116760254, 'learning_rate': 2.6485436893203886e-06, 'epoch': 9.91}\n",
      "{'loss': 0.5584, 'grad_norm': 24.572437286376953, 'learning_rate': 2.6242718446601944e-06, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60308e84553b4672a0dca83f6681e14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.939357876777649, 'eval_accuracy': 0.45416666666666666, 'eval_runtime': 3.0349, 'eval_samples_per_second': 158.158, 'eval_steps_per_second': 19.77, 'epoch': 10.0}\n",
      "{'loss': 0.5791, 'grad_norm': 208.02886962890625, 'learning_rate': 2.6e-06, 'epoch': 10.09}\n",
      "{'loss': 0.5321, 'grad_norm': 15.234776496887207, 'learning_rate': 2.5757281553398062e-06, 'epoch': 10.19}\n",
      "{'loss': 0.5773, 'grad_norm': 54.798065185546875, 'learning_rate': 2.551456310679612e-06, 'epoch': 10.28}\n",
      "{'loss': 0.6048, 'grad_norm': 266.93304443359375, 'learning_rate': 2.5271844660194177e-06, 'epoch': 10.37}\n",
      "{'loss': 0.6032, 'grad_norm': 194.722412109375, 'learning_rate': 2.5029126213592234e-06, 'epoch': 10.46}\n",
      "{'loss': 0.5976, 'grad_norm': 343.4665832519531, 'learning_rate': 2.478640776699029e-06, 'epoch': 10.56}\n",
      "{'loss': 0.6328, 'grad_norm': 31.19542694091797, 'learning_rate': 2.454368932038835e-06, 'epoch': 10.65}\n",
      "{'loss': 0.57, 'grad_norm': 249.82583618164062, 'learning_rate': 2.430097087378641e-06, 'epoch': 10.74}\n",
      "{'loss': 0.53, 'grad_norm': 15.226202964782715, 'learning_rate': 2.4058252427184468e-06, 'epoch': 10.83}\n",
      "{'loss': 0.4447, 'grad_norm': 246.20018005371094, 'learning_rate': 2.3815533980582525e-06, 'epoch': 10.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1684663b02490482ce5126ddf30f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0023016929626465, 'eval_accuracy': 0.4625, 'eval_runtime': 2.9909, 'eval_samples_per_second': 160.488, 'eval_steps_per_second': 20.061, 'epoch': 11.0}\n",
      "{'loss': 0.597, 'grad_norm': 110.32918548583984, 'learning_rate': 2.3572815533980582e-06, 'epoch': 11.02}\n",
      "{'loss': 0.5738, 'grad_norm': 188.2819061279297, 'learning_rate': 2.3330097087378644e-06, 'epoch': 11.11}\n",
      "{'loss': 0.5846, 'grad_norm': 58.788185119628906, 'learning_rate': 2.30873786407767e-06, 'epoch': 11.2}\n",
      "{'loss': 0.5479, 'grad_norm': 219.551025390625, 'learning_rate': 2.284466019417476e-06, 'epoch': 11.3}\n",
      "{'loss': 0.548, 'grad_norm': 75.92700958251953, 'learning_rate': 2.2601941747572816e-06, 'epoch': 11.39}\n",
      "{'loss': 0.5144, 'grad_norm': 38.188663482666016, 'learning_rate': 2.2359223300970877e-06, 'epoch': 11.48}\n",
      "{'loss': 0.5095, 'grad_norm': 182.33888244628906, 'learning_rate': 2.2116504854368934e-06, 'epoch': 11.57}\n",
      "{'loss': 0.5317, 'grad_norm': 414.754638671875, 'learning_rate': 2.187378640776699e-06, 'epoch': 11.67}\n",
      "{'loss': 0.5832, 'grad_norm': 28.907751083374023, 'learning_rate': 2.163106796116505e-06, 'epoch': 11.76}\n",
      "{'loss': 0.5907, 'grad_norm': 133.30056762695312, 'learning_rate': 2.138834951456311e-06, 'epoch': 11.85}\n",
      "{'loss': 0.5765, 'grad_norm': 260.79998779296875, 'learning_rate': 2.1145631067961168e-06, 'epoch': 11.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83db3b31d6344f9eb18c5a85c050e200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0447170734405518, 'eval_accuracy': 0.45625, 'eval_runtime': 3.1252, 'eval_samples_per_second': 153.592, 'eval_steps_per_second': 19.199, 'epoch': 12.0}\n",
      "{'loss': 0.5363, 'grad_norm': 3.0669565200805664, 'learning_rate': 2.0902912621359225e-06, 'epoch': 12.04}\n",
      "{'loss': 0.5374, 'grad_norm': 114.23990631103516, 'learning_rate': 2.0660194174757282e-06, 'epoch': 12.13}\n",
      "{'loss': 0.5584, 'grad_norm': 53.618316650390625, 'learning_rate': 2.0417475728155344e-06, 'epoch': 12.22}\n",
      "{'loss': 0.5462, 'grad_norm': 48.594085693359375, 'learning_rate': 2.01747572815534e-06, 'epoch': 12.31}\n",
      "{'loss': 0.4743, 'grad_norm': 146.4084930419922, 'learning_rate': 1.9936893203883497e-06, 'epoch': 12.41}\n",
      "{'loss': 0.5011, 'grad_norm': 80.73147583007812, 'learning_rate': 1.969417475728156e-06, 'epoch': 12.5}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 62\u001b[0m\n\u001b[0;32m     49\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     50\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     51\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m \n\u001b[0;32m     59\u001b[0m )\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\transformers\\trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\transformers\\trainer.py:2203\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2202\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 2203\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2206\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2207\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2209\u001b[0m ):\n\u001b[0;32m   2210\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2211\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mf:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\transformers\\trainer.py:3147\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   3145\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32mf:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\accelerate\\accelerator.py:2011\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2009\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2011\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2013\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\torch\\_tensor.py:523\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    515\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    516\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    522\u001b[0m     )\n\u001b[1;32m--> 523\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py:767\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    765\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    768\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    769\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model = model.to('cuda')\n",
    "\n",
    "import json\n",
    "import wandb\n",
    "\n",
    "run = wandb.init(\n",
    "    project='Cam01', \n",
    "    name=\"031\", \n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    metric = load_metric(\"accuracy\")\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = metric.compute(predictions=predictions, references=labels)\n",
    "    return {\"accuracy\": accuracy['accuracy']}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    gradient_accumulation_steps=1,\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.005,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    learning_rate=5e-6,\n",
    "    #adam_epsilon=10e-3,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "args_dict = training_args.to_dict()\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open('training_arguments031.json', 'w') as f:\n",
    "    json.dump(args_dict, f, indent=4)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    #tokenizer='camembert-base',\n",
    "    #data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=30)]\n",
    "\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756448d51beb4cad8f835e66719c4267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=0.9958810068649886, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">017</strong> at: <a href='https://wandb.ai/m-kai-d/Cam01/runs/qtpt1wk1' target=\"_blank\">https://wandb.ai/m-kai-d/Cam01/runs/qtpt1wk1</a><br/> View project at: <a href='https://wandb.ai/m-kai-d/Cam01' target=\"_blank\">https://wandb.ai/m-kai-d/Cam01</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240520_214515-qtpt1wk1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#don't do before the eval\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c630215789dc4eaeb3bf5f5b7e75a0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\projects\\Matthias\\proj_01\\.venv\\lib\\site-packages\\datasets\\load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results: {'eval_loss': 0.3416188657283783, 'eval_accuracy': 0.9552083333333333, 'eval_runtime': 3.9385, 'eval_samples_per_second': 243.747, 'eval_steps_per_second': 30.468, 'epoch': 8.0}\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(\"Validation Results:\", eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for unlabelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6679427f75c544d39d27f7ef8b6614f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import CamembertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "#------------ must change model\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "\n",
    "max_length = 512 \n",
    "unlabelled_encodings = tokenizer(list(unlabelled_data_pd['sentence']), truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "dataset = SimpleDataset(unlabelled_encodings)\n",
    "\n",
    "predictions = trainer.predict(dataset)\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "difficulty_levels = {0: 'A1', 1: 'A2', 2: 'B1', 3: 'B2', 4: 'C1', 5: 'C2'}\n",
    "predicted_difficulties = [difficulty_levels[label] for label in predicted_labels]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': unlabelled_data_pd['id'],\n",
    "    'difficulty': predicted_difficulties\n",
    "})\n",
    "\n",
    "submission_df.to_csv('F:\\projects\\Matthias\\proj_01\\cam01\\submission_CamemBERT_018.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
